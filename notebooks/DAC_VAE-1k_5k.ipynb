{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df12d45c-a97d-4b67-a6ae-e6f4f35d3d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CUDA DIAGNOSTICS\n",
      "================================================================================\n",
      "\n",
      "CUDA Available: True\n",
      "CUDA Version: 12.6\n",
      "PyTorch Version: 2.9.1+cu126\n",
      "Number of GPUs: 1\n",
      "\n",
      "--- GPU 0 ---\n",
      "Name: NVIDIA RTX A1000\n",
      "Capability: (8, 6)\n",
      "Total Memory: 8.00 GB\n",
      "Available Memory: 7.03 GB\n",
      "Allocated Memory: 0.00 GB\n",
      "✓ Can create tensors on GPU 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CUDA DIAGNOSTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check CUDA availability\n",
    "print(f\"\\nCUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    \n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"\\n--- GPU {i} ---\")\n",
    "        print(f\"Name: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"Capability: {torch.cuda.get_device_capability(i)}\")\n",
    "        \n",
    "        # Memory info\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"Total Memory: {props.total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"Available Memory: {torch.cuda.mem_get_info(i)[0] / 1024**3:.2f} GB\")\n",
    "        print(f\"Allocated Memory: {torch.cuda.memory_allocated(i) / 1024**3:.2f} GB\")\n",
    "        \n",
    "        # Test tensor creation\n",
    "        try:\n",
    "            test_tensor = torch.randn(100, 100).cuda(i)\n",
    "            print(f\"✓ Can create tensors on GPU {i}\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error creating tensor: {e}\")\n",
    "else:\n",
    "    print(\"\\n✗ CUDA is NOT available!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d15bf932-78c2-492a-b0b2-08664e9c0249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Memory: 5.88 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Kill all CUDA processes\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.reset_accumulated_memory_stats()\n",
    "\n",
    "print(f\"Available Memory: {torch.cuda.mem_get_info(0)[0] / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a13a9abc-a3db-4b11-a6d9-4ab0a5d6d794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.9.1-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting einops\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting descript-audio-codec\n",
      "  Downloading descript_audio_codec-1.0.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: torch==2.9.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torchaudio) (2.9.1+cu126)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.9.1->torchaudio) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.9.1->torchaudio) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.9.1->torchaudio) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.9.1->torchaudio) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.9.1->torchaudio) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.9.1->torchaudio) (2025.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.9.1->torchaudio) (70.2.0)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (6.0.3)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Collecting argbind>=0.3.7 (from descript-audio-codec)\n",
      "  Downloading argbind-0.3.9.tar.gz (17 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting descript-audiotools>=0.7.2 (from descript-audio-codec)\n",
      "  Downloading descript_audiotools-0.7.2-py2.py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting docstring-parser (from argbind>=0.3.7->descript-audio-codec)\n",
      "  Using cached docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting soundfile (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Collecting pyloudnorm (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading pyloudnorm-0.1.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting importlib-resources (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from descript-audiotools>=0.7.2->descript-audio-codec) (1.16.3)\n",
      "Collecting julius (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting ffmpy (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading ffmpy-1.0.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: ipython in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from descript-audiotools>=0.7.2->descript-audio-codec) (9.8.0)\n",
      "Collecting rich (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from descript-audiotools>=0.7.2->descript-audio-codec) (3.10.8)\n",
      "Collecting librosa (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting pystoi (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading pystoi-0.4.1-py2.py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting torch-stoi (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading torch_stoi-0.2.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting flatten-dict (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading flatten_dict-0.4.2-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting markdown2 (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading markdown2-2.5.4-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting randomname (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading randomname-0.2.1.tar.gz (64 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting protobuf<3.20,>=3.9.2 (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading protobuf-3.19.6-py2.py3-none-any.whl.metadata (828 bytes)\n",
      "Collecting tensorboard (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from sympy>=1.13.3->torch==2.9.1->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: six<2.0,>=1.12 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from flatten-dict->descript-audiotools>=0.7.2->descript-audio-codec) (1.17.0)\n",
      "Requirement already satisfied: decorator>=4.3.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipython->descript-audiotools>=0.7.2->descript-audio-codec) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipython->descript-audiotools>=0.7.2->descript-audio-codec) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipython->descript-audiotools>=0.7.2->descript-audio-codec) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipython->descript-audiotools>=0.7.2->descript-audio-codec) (0.2.1)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipython->descript-audiotools>=0.7.2->descript-audio-codec) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipython->descript-audiotools>=0.7.2->descript-audio-codec) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipython->descript-audiotools>=0.7.2->descript-audio-codec) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from ipython->descript-audiotools>=0.7.2->descript-audio-codec) (5.14.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch==2.9.1->torchaudio) (2.1.5)\n",
      "Collecting audioread>=2.1.9 (from librosa->descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading audioread-3.1.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting numba>=0.51.0 (from librosa->descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading numba-0.63.1-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from librosa->descript-audiotools>=0.7.2->descript-audio-codec) (1.8.0)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from librosa->descript-audiotools>=0.7.2->descript-audio-codec) (1.5.3)\n",
      "Collecting pooch>=1.1 (from librosa->descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa->descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading soxr-1.0.0-cp312-abi3-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting lazy_loader>=0.1 (from librosa->descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa->descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading msgpack-1.1.2-cp312-cp312-win_amd64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from soundfile->descript-audiotools>=0.7.2->descript-audio-codec) (2.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->descript-audiotools>=0.7.2->descript-audio-codec) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->descript-audiotools>=0.7.2->descript-audio-codec) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->descript-audiotools>=0.7.2->descript-audio-codec) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->descript-audiotools>=0.7.2->descript-audio-codec) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->descript-audiotools>=0.7.2->descript-audio-codec) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->descript-audiotools>=0.7.2->descript-audio-codec) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->descript-audiotools>=0.7.2->descript-audio-codec) (2.9.0.post0)\n",
      "Collecting future>=0.16.0 (from pyloudnorm->descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting fire (from randomname->descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard->descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard->descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading grpcio-1.76.0-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard->descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Using cached markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard->descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Using cached werkzeug-3.1.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from cffi>=1.0->soundfile->descript-audiotools>=0.7.2->descript-audio-codec) (2.23)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from jedi>=0.18.1->ipython->descript-audiotools>=0.7.2->descript-audio-codec) (0.8.5)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting llvmlite<0.47,>=0.46.0dev0 (from numba>=0.51.0->librosa->descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading llvmlite-0.46.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pooch>=1.1->librosa->descript-audiotools>=0.7.2->descript-audio-codec) (4.5.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython->descript-audiotools>=0.7.2->descript-audio-codec) (0.2.14)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn>=1.1.0->librosa->descript-audiotools>=0.7.2->descript-audio-codec) (3.6.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from stack_data>=0.6.0->ipython->descript-audiotools>=0.7.2->descript-audio-codec) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from stack_data>=0.6.0->ipython->descript-audiotools>=0.7.2->descript-audio-codec) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from stack_data>=0.6.0->ipython->descript-audiotools>=0.7.2->descript-audio-codec) (0.2.3)\n",
      "Collecting termcolor (from fire->randomname->descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Using cached termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Downloading torchaudio-2.9.1-cp312-cp312-win_amd64.whl (665 kB)\n",
      "   ---------------------------------------- 0.0/665.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/665.3 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 262.1/665.3 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 262.1/665.3 kB ? eta -:--:--\n",
      "   ----------------------------- -------- 524.3/665.3 kB 799.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- 665.3/665.3 kB 861.5 kB/s eta 0:00:00\n",
      "Using cached transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading descript_audio_codec-1.0.0-py3-none-any.whl (26 kB)\n",
      "Downloading descript_audiotools-0.7.2-py2.py3-none-any.whl (106 kB)\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Downloading regex-2025.11.3-cp312-cp312-win_amd64.whl (277 kB)\n",
      "Using cached safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "Downloading protobuf-3.19.6-py2.py3-none-any.whl (162 kB)\n",
      "Using cached docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading ffmpy-1.0.0-py3-none-any.whl (5.6 kB)\n",
      "Downloading flatten_dict-0.4.2-py2.py3-none-any.whl (9.7 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.5/1.0 MB 837.5 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.8/1.0 MB 987.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 1.0 MB/s eta 0:00:00\n",
      "Downloading markdown2-2.5.4-py3-none-any.whl (49 kB)\n",
      "Downloading pyloudnorm-0.1.1-py3-none-any.whl (9.6 kB)\n",
      "Downloading pystoi-0.4.1-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Downloading torch_stoi-0.2.3-py3-none-any.whl (8.1 kB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading audioread-3.1.0-py3-none-any.whl (23 kB)\n",
      "Using cached future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Downloading grpcio-1.76.0-cp312-cp312-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.5/4.7 MB 215.2 kB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 0.5/4.7 MB 215.2 kB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 0.5/4.7 MB 215.2 kB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 0.5/4.7 MB 215.2 kB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 0.5/4.7 MB 215.2 kB/s eta 0:00:20\n",
      "   ------ --------------------------------- 0.8/4.7 MB 236.4 kB/s eta 0:00:17\n",
      "   ------ --------------------------------- 0.8/4.7 MB 236.4 kB/s eta 0:00:17\n",
      "   ------ --------------------------------- 0.8/4.7 MB 236.4 kB/s eta 0:00:17\n",
      "   -------- ------------------------------- 1.0/4.7 MB 265.0 kB/s eta 0:00:14\n",
      "   -------- ------------------------------- 1.0/4.7 MB 265.0 kB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 1.3/4.7 MB 319.6 kB/s eta 0:00:11\n",
      "   ------------- -------------------------- 1.6/4.7 MB 361.6 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 1.6/4.7 MB 361.6 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 1.6/4.7 MB 361.6 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 1.6/4.7 MB 361.6 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 1.6/4.7 MB 361.6 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 1.6/4.7 MB 361.6 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 1.6/4.7 MB 361.6 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 1.6/4.7 MB 361.6 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 1.6/4.7 MB 361.6 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 1.6/4.7 MB 361.6 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 1.6/4.7 MB 361.6 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 1.6/4.7 MB 361.6 kB/s eta 0:00:09\n",
      "   --------------- ------------------------ 1.8/4.7 MB 257.5 kB/s eta 0:00:12\n",
      "   --------------- ------------------------ 1.8/4.7 MB 257.5 kB/s eta 0:00:12\n",
      "   --------------- ------------------------ 1.8/4.7 MB 257.5 kB/s eta 0:00:12\n",
      "   --------------- ------------------------ 1.8/4.7 MB 257.5 kB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 2.1/4.7 MB 266.3 kB/s eta 0:00:10\n",
      "   -------------------- ------------------- 2.4/4.7 MB 287.4 kB/s eta 0:00:09\n",
      "   -------------------- ------------------- 2.4/4.7 MB 287.4 kB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 2.6/4.7 MB 305.1 kB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 2.6/4.7 MB 305.1 kB/s eta 0:00:07\n",
      "   ------------------------ --------------- 2.9/4.7 MB 322.0 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 2.9/4.7 MB 322.0 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 2.9/4.7 MB 322.0 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 3.1/4.7 MB 330.8 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 3.1/4.7 MB 330.8 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 3.1/4.7 MB 330.8 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 3.1/4.7 MB 330.8 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 3.1/4.7 MB 330.8 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 3.1/4.7 MB 330.8 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 3.1/4.7 MB 330.8 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 3.1/4.7 MB 330.8 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 3.1/4.7 MB 330.8 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 3.1/4.7 MB 330.8 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 3.4/4.7 MB 290.1 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 3.4/4.7 MB 290.1 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 3.4/4.7 MB 290.1 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 3.7/4.7 MB 292.8 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 3.7/4.7 MB 292.8 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 3.7/4.7 MB 292.8 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 3.9/4.7 MB 302.3 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 3.9/4.7 MB 302.3 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 3.9/4.7 MB 302.3 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 4.2/4.7 MB 308.0 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 4.2/4.7 MB 308.0 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 4.5/4.7 MB 316.2 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.5/4.7 MB 316.2 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.5/4.7 MB 316.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 316.6 kB/s eta 0:00:00\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Using cached markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading msgpack-1.1.2-cp312-cp312-win_amd64.whl (72 kB)\n",
      "Downloading numba-0.63.1-cp312-cp312-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.8 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.8 MB 699.0 kB/s eta 0:00:04\n",
      "   ------- -------------------------------- 0.5/2.8 MB 699.0 kB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 0.8/2.8 MB 657.8 kB/s eta 0:00:03\n",
      "   --------------- ------------------------ 1.0/2.8 MB 645.1 kB/s eta 0:00:03\n",
      "   --------------- ------------------------ 1.0/2.8 MB 645.1 kB/s eta 0:00:03\n",
      "   --------------- ------------------------ 1.0/2.8 MB 645.1 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 1.3/2.8 MB 621.2 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 1.3/2.8 MB 621.2 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 1.3/2.8 MB 621.2 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 1.3/2.8 MB 621.2 kB/s eta 0:00:03\n",
      "   ------------------- -------------------- 1.3/2.8 MB 621.2 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 1.6/2.8 MB 458.5 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 1.6/2.8 MB 458.5 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 1.6/2.8 MB 458.5 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 1.6/2.8 MB 458.5 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 1.6/2.8 MB 458.5 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 1.6/2.8 MB 458.5 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 1.6/2.8 MB 458.5 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 1.6/2.8 MB 458.5 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 1.6/2.8 MB 458.5 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 1.6/2.8 MB 458.5 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 1.8/2.8 MB 313.6 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 1.8/2.8 MB 313.6 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 1.8/2.8 MB 313.6 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 1.8/2.8 MB 313.6 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 1.8/2.8 MB 313.6 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 2.1/2.8 MB 299.6 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 2.1/2.8 MB 299.6 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 2.4/2.8 MB 322.6 kB/s eta 0:00:02\n",
      "   ---------------------------------------- 2.8/2.8 MB 363.6 kB/s eta 0:00:00\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading soxr-1.0.0-cp312-abi3-win_amd64.whl (172 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.1.4-py3-none-any.whl (224 kB)\n",
      "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
      "Downloading llvmlite-0.46.0-cp312-cp312-win_amd64.whl (38.1 MB)\n",
      "   ---------------------------------------- 0.0/38.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/38.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/38.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/38.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/38.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/38.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/38.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/38.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/38.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/38.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/38.1 MB 250.4 kB/s eta 0:02:31\n",
      "    --------------------------------------- 0.5/38.1 MB 250.4 kB/s eta 0:02:31\n",
      "    --------------------------------------- 0.5/38.1 MB 250.4 kB/s eta 0:02:31\n",
      "    --------------------------------------- 0.8/38.1 MB 302.2 kB/s eta 0:02:04\n",
      "    --------------------------------------- 0.8/38.1 MB 302.2 kB/s eta 0:02:04\n",
      "   - -------------------------------------- 1.0/38.1 MB 364.8 kB/s eta 0:01:42\n",
      "   - -------------------------------------- 1.3/38.1 MB 438.6 kB/s eta 0:01:24\n",
      "   - -------------------------------------- 1.6/38.1 MB 502.2 kB/s eta 0:01:13\n",
      "   - -------------------------------------- 1.6/38.1 MB 502.2 kB/s eta 0:01:13\n",
      "   - -------------------------------------- 1.8/38.1 MB 535.4 kB/s eta 0:01:08\n",
      "   - -------------------------------------- 1.8/38.1 MB 535.4 kB/s eta 0:01:08\n",
      "   - -------------------------------------- 1.8/38.1 MB 535.4 kB/s eta 0:01:08\n",
      "   - -------------------------------------- 1.8/38.1 MB 535.4 kB/s eta 0:01:08\n",
      "   - -------------------------------------- 1.8/38.1 MB 535.4 kB/s eta 0:01:08\n",
      "   - -------------------------------------- 1.8/38.1 MB 535.4 kB/s eta 0:01:08\n",
      "   - -------------------------------------- 1.8/38.1 MB 535.4 kB/s eta 0:01:08\n",
      "   - -------------------------------------- 1.8/38.1 MB 535.4 kB/s eta 0:01:08\n",
      "   - -------------------------------------- 1.8/38.1 MB 535.4 kB/s eta 0:01:08\n",
      "   -- ------------------------------------- 2.1/38.1 MB 370.5 kB/s eta 0:01:38\n",
      "   -- ------------------------------------- 2.1/38.1 MB 370.5 kB/s eta 0:01:38\n",
      "   -- ------------------------------------- 2.1/38.1 MB 370.5 kB/s eta 0:01:38\n",
      "   -- ------------------------------------- 2.1/38.1 MB 370.5 kB/s eta 0:01:38\n",
      "   -- ------------------------------------- 2.1/38.1 MB 370.5 kB/s eta 0:01:38\n",
      "   -- ------------------------------------- 2.1/38.1 MB 370.5 kB/s eta 0:01:38\n",
      "   -- ------------------------------------- 2.4/38.1 MB 335.5 kB/s eta 0:01:47\n",
      "   -- ------------------------------------- 2.4/38.1 MB 335.5 kB/s eta 0:01:47\n",
      "   -- ------------------------------------- 2.4/38.1 MB 335.5 kB/s eta 0:01:47\n",
      "   -- ------------------------------------- 2.4/38.1 MB 335.5 kB/s eta 0:01:47\n",
      "   -- ------------------------------------- 2.6/38.1 MB 337.0 kB/s eta 0:01:46\n",
      "   --- ------------------------------------ 2.9/38.1 MB 354.7 kB/s eta 0:01:40\n",
      "   --- ------------------------------------ 2.9/38.1 MB 354.7 kB/s eta 0:01:40\n",
      "   --- ------------------------------------ 2.9/38.1 MB 354.7 kB/s eta 0:01:40\n",
      "   --- ------------------------------------ 3.1/38.1 MB 362.6 kB/s eta 0:01:37\n",
      "   --- ------------------------------------ 3.1/38.1 MB 362.6 kB/s eta 0:01:37\n",
      "   --- ------------------------------------ 3.1/38.1 MB 362.6 kB/s eta 0:01:37\n",
      "   --- ------------------------------------ 3.1/38.1 MB 362.6 kB/s eta 0:01:37\n",
      "   --- ------------------------------------ 3.1/38.1 MB 362.6 kB/s eta 0:01:37\n",
      "   --- ------------------------------------ 3.1/38.1 MB 362.6 kB/s eta 0:01:37\n",
      "   --- ------------------------------------ 3.1/38.1 MB 362.6 kB/s eta 0:01:37\n",
      "   --- ------------------------------------ 3.1/38.1 MB 362.6 kB/s eta 0:01:37\n",
      "   --- ------------------------------------ 3.1/38.1 MB 362.6 kB/s eta 0:01:37\n",
      "   --- ------------------------------------ 3.1/38.1 MB 362.6 kB/s eta 0:01:37\n",
      "   --- ------------------------------------ 3.1/38.1 MB 362.6 kB/s eta 0:01:37\n",
      "   --- ------------------------------------ 3.4/38.1 MB 303.2 kB/s eta 0:01:55\n",
      "   --- ------------------------------------ 3.4/38.1 MB 303.2 kB/s eta 0:01:55\n",
      "   --- ------------------------------------ 3.4/38.1 MB 303.2 kB/s eta 0:01:55\n",
      "   --- ------------------------------------ 3.4/38.1 MB 303.2 kB/s eta 0:01:55\n",
      "   --- ------------------------------------ 3.4/38.1 MB 303.2 kB/s eta 0:01:55\n",
      "   --- ------------------------------------ 3.7/38.1 MB 300.0 kB/s eta 0:01:55\n",
      "   --- ------------------------------------ 3.7/38.1 MB 300.0 kB/s eta 0:01:55\n",
      "   --- ------------------------------------ 3.7/38.1 MB 300.0 kB/s eta 0:01:55\n",
      "   ---- ----------------------------------- 3.9/38.1 MB 303.9 kB/s eta 0:01:53\n",
      "   ---- ----------------------------------- 3.9/38.1 MB 303.9 kB/s eta 0:01:53\n",
      "   ---- ----------------------------------- 4.2/38.1 MB 314.6 kB/s eta 0:01:48\n",
      "   ---- ----------------------------------- 4.2/38.1 MB 314.6 kB/s eta 0:01:48\n",
      "   ---- ----------------------------------- 4.2/38.1 MB 314.6 kB/s eta 0:01:48\n",
      "   ---- ----------------------------------- 4.5/38.1 MB 322.2 kB/s eta 0:01:45\n",
      "   ---- ----------------------------------- 4.5/38.1 MB 322.2 kB/s eta 0:01:45\n",
      "   ---- ----------------------------------- 4.5/38.1 MB 322.2 kB/s eta 0:01:45\n",
      "   ---- ----------------------------------- 4.5/38.1 MB 322.2 kB/s eta 0:01:45\n",
      "   ---- ----------------------------------- 4.5/38.1 MB 322.2 kB/s eta 0:01:45\n",
      "   ---- ----------------------------------- 4.5/38.1 MB 322.2 kB/s eta 0:01:45\n",
      "   ---- ----------------------------------- 4.5/38.1 MB 322.2 kB/s eta 0:01:45\n",
      "   ---- ----------------------------------- 4.5/38.1 MB 322.2 kB/s eta 0:01:45\n",
      "   ---- ----------------------------------- 4.5/38.1 MB 322.2 kB/s eta 0:01:45\n",
      "   ---- ----------------------------------- 4.5/38.1 MB 322.2 kB/s eta 0:01:45\n",
      "   ---- ----------------------------------- 4.5/38.1 MB 322.2 kB/s eta 0:01:45\n",
      "   ---- ----------------------------------- 4.7/38.1 MB 289.9 kB/s eta 0:01:56\n",
      "   ---- ----------------------------------- 4.7/38.1 MB 289.9 kB/s eta 0:01:56\n",
      "   ---- ----------------------------------- 4.7/38.1 MB 289.9 kB/s eta 0:01:56\n",
      "   ----- ---------------------------------- 5.0/38.1 MB 291.5 kB/s eta 0:01:54\n",
      "   ----- ---------------------------------- 5.0/38.1 MB 291.5 kB/s eta 0:01:54\n",
      "   ----- ---------------------------------- 5.0/38.1 MB 291.5 kB/s eta 0:01:54\n",
      "   ----- ---------------------------------- 5.2/38.1 MB 296.2 kB/s eta 0:01:52\n",
      "   ----- ---------------------------------- 5.2/38.1 MB 296.2 kB/s eta 0:01:52\n",
      "   ----- ---------------------------------- 5.2/38.1 MB 296.2 kB/s eta 0:01:52\n",
      "   ----- ---------------------------------- 5.5/38.1 MB 299.6 kB/s eta 0:01:49\n",
      "   ----- ---------------------------------- 5.5/38.1 MB 299.6 kB/s eta 0:01:49\n",
      "   ----- ---------------------------------- 5.5/38.1 MB 299.6 kB/s eta 0:01:49\n",
      "   ------ --------------------------------- 5.8/38.1 MB 303.5 kB/s eta 0:01:47\n",
      "   ------ --------------------------------- 5.8/38.1 MB 303.5 kB/s eta 0:01:47\n",
      "   ------ --------------------------------- 5.8/38.1 MB 303.5 kB/s eta 0:01:47\n",
      "   ------ --------------------------------- 5.8/38.1 MB 303.5 kB/s eta 0:01:47\n",
      "   ------ --------------------------------- 5.8/38.1 MB 303.5 kB/s eta 0:01:47\n",
      "   ------ --------------------------------- 5.8/38.1 MB 303.5 kB/s eta 0:01:47\n",
      "   ------ --------------------------------- 5.8/38.1 MB 303.5 kB/s eta 0:01:47\n",
      "   ------ --------------------------------- 6.0/38.1 MB 294.6 kB/s eta 0:01:50\n",
      "   ------ --------------------------------- 6.0/38.1 MB 294.6 kB/s eta 0:01:50\n",
      "   ------ --------------------------------- 6.0/38.1 MB 294.6 kB/s eta 0:01:50\n",
      "   ------ --------------------------------- 6.0/38.1 MB 294.6 kB/s eta 0:01:50\n",
      "   ------ --------------------------------- 6.0/38.1 MB 294.6 kB/s eta 0:01:50\n",
      "   ------ --------------------------------- 6.0/38.1 MB 294.6 kB/s eta 0:01:50\n",
      "   ------ --------------------------------- 6.0/38.1 MB 294.6 kB/s eta 0:01:50\n",
      "   ------ --------------------------------- 6.3/38.1 MB 284.6 kB/s eta 0:01:52\n",
      "   ------ --------------------------------- 6.3/38.1 MB 284.6 kB/s eta 0:01:52\n",
      "   ------ --------------------------------- 6.3/38.1 MB 284.6 kB/s eta 0:01:52\n",
      "   ------ --------------------------------- 6.6/38.1 MB 289.0 kB/s eta 0:01:50\n",
      "   ------ --------------------------------- 6.6/38.1 MB 289.0 kB/s eta 0:01:50\n",
      "   ------- -------------------------------- 6.8/38.1 MB 295.2 kB/s eta 0:01:47\n",
      "   ------- -------------------------------- 6.8/38.1 MB 295.2 kB/s eta 0:01:47\n",
      "   ------- -------------------------------- 7.1/38.1 MB 301.0 kB/s eta 0:01:44\n",
      "   ------- -------------------------------- 7.1/38.1 MB 301.0 kB/s eta 0:01:44\n",
      "   ------- -------------------------------- 7.3/38.1 MB 305.7 kB/s eta 0:01:41\n",
      "   ------- -------------------------------- 7.3/38.1 MB 305.7 kB/s eta 0:01:41\n",
      "   ------- -------------------------------- 7.3/38.1 MB 305.7 kB/s eta 0:01:41\n",
      "   ------- -------------------------------- 7.3/38.1 MB 305.7 kB/s eta 0:01:41\n",
      "   ------- -------------------------------- 7.6/38.1 MB 306.6 kB/s eta 0:01:40\n",
      "   ------- -------------------------------- 7.6/38.1 MB 306.6 kB/s eta 0:01:40\n",
      "   -------- ------------------------------- 7.9/38.1 MB 311.3 kB/s eta 0:01:38\n",
      "   -------- ------------------------------- 7.9/38.1 MB 311.3 kB/s eta 0:01:38\n",
      "   -------- ------------------------------- 7.9/38.1 MB 311.3 kB/s eta 0:01:38\n",
      "   -------- ------------------------------- 7.9/38.1 MB 311.3 kB/s eta 0:01:38\n",
      "   -------- ------------------------------- 7.9/38.1 MB 311.3 kB/s eta 0:01:38\n",
      "   -------- ------------------------------- 7.9/38.1 MB 311.3 kB/s eta 0:01:38\n",
      "   -------- ------------------------------- 8.1/38.1 MB 308.2 kB/s eta 0:01:38\n",
      "   -------- ------------------------------- 8.1/38.1 MB 308.2 kB/s eta 0:01:38\n",
      "   -------- ------------------------------- 8.4/38.1 MB 312.6 kB/s eta 0:01:36\n",
      "   -------- ------------------------------- 8.4/38.1 MB 312.6 kB/s eta 0:01:36\n",
      "   --------- ------------------------------ 8.7/38.1 MB 317.1 kB/s eta 0:01:33\n",
      "   --------- ------------------------------ 8.7/38.1 MB 317.1 kB/s eta 0:01:33\n",
      "   --------- ------------------------------ 8.7/38.1 MB 317.1 kB/s eta 0:01:33\n",
      "   --------- ------------------------------ 8.9/38.1 MB 319.3 kB/s eta 0:01:32\n",
      "   --------- ------------------------------ 8.9/38.1 MB 319.3 kB/s eta 0:01:32\n",
      "   --------- ------------------------------ 9.2/38.1 MB 323.7 kB/s eta 0:01:30\n",
      "   --------- ------------------------------ 9.4/38.1 MB 329.5 kB/s eta 0:01:28\n",
      "   --------- ------------------------------ 9.4/38.1 MB 329.5 kB/s eta 0:01:28\n",
      "   --------- ------------------------------ 9.4/38.1 MB 329.5 kB/s eta 0:01:28\n",
      "   --------- ------------------------------ 9.4/38.1 MB 329.5 kB/s eta 0:01:28\n",
      "   --------- ------------------------------ 9.4/38.1 MB 329.5 kB/s eta 0:01:28\n",
      "   --------- ------------------------------ 9.4/38.1 MB 329.5 kB/s eta 0:01:28\n",
      "   --------- ------------------------------ 9.4/38.1 MB 329.5 kB/s eta 0:01:28\n",
      "   --------- ------------------------------ 9.4/38.1 MB 329.5 kB/s eta 0:01:28\n",
      "   --------- ------------------------------ 9.4/38.1 MB 329.5 kB/s eta 0:01:28\n",
      "   ---------- ----------------------------- 9.7/38.1 MB 317.5 kB/s eta 0:01:30\n",
      "   ---------- ----------------------------- 9.7/38.1 MB 317.5 kB/s eta 0:01:30\n",
      "   ---------- ----------------------------- 9.7/38.1 MB 317.5 kB/s eta 0:01:30\n",
      "   ---------- ----------------------------- 9.7/38.1 MB 317.5 kB/s eta 0:01:30\n",
      "   ---------- ----------------------------- 10.0/38.1 MB 320.6 kB/s eta 0:01:28\n",
      "   ---------- ----------------------------- 10.0/38.1 MB 320.6 kB/s eta 0:01:28\n",
      "   ---------- ----------------------------- 10.0/38.1 MB 320.6 kB/s eta 0:01:28\n",
      "   ---------- ----------------------------- 10.2/38.1 MB 320.6 kB/s eta 0:01:28\n",
      "   ---------- ----------------------------- 10.2/38.1 MB 320.6 kB/s eta 0:01:28\n",
      "   ---------- ----------------------------- 10.2/38.1 MB 320.6 kB/s eta 0:01:28\n",
      "   ---------- ----------------------------- 10.2/38.1 MB 320.6 kB/s eta 0:01:28\n",
      "   ---------- ----------------------------- 10.5/38.1 MB 314.9 kB/s eta 0:01:28\n",
      "   ---------- ----------------------------- 10.5/38.1 MB 314.9 kB/s eta 0:01:28\n",
      "   ----------- ---------------------------- 10.7/38.1 MB 307.9 kB/s eta 0:01:29\n",
      "   ----------- ---------------------------- 11.0/38.1 MB 308.9 kB/s eta 0:01:28\n",
      "   ----------- ---------------------------- 11.3/38.1 MB 314.9 kB/s eta 0:01:26\n",
      "   ----------- ---------------------------- 11.3/38.1 MB 314.9 kB/s eta 0:01:26\n",
      "   ----------- ---------------------------- 11.3/38.1 MB 314.9 kB/s eta 0:01:26\n",
      "   ----------- ---------------------------- 11.3/38.1 MB 314.9 kB/s eta 0:01:26\n",
      "   ------------ --------------------------- 11.5/38.1 MB 327.5 kB/s eta 0:01:22\n",
      "   ------------ --------------------------- 11.5/38.1 MB 327.5 kB/s eta 0:01:22\n",
      "   ------------ --------------------------- 11.5/38.1 MB 327.5 kB/s eta 0:01:22\n",
      "   ------------ --------------------------- 11.5/38.1 MB 327.5 kB/s eta 0:01:22\n",
      "   ------------ --------------------------- 11.5/38.1 MB 327.5 kB/s eta 0:01:22\n",
      "   ------------ --------------------------- 11.5/38.1 MB 327.5 kB/s eta 0:01:22\n",
      "   ------------ --------------------------- 11.8/38.1 MB 326.5 kB/s eta 0:01:21\n",
      "   ------------ --------------------------- 11.8/38.1 MB 326.5 kB/s eta 0:01:21\n",
      "   ------------ --------------------------- 12.1/38.1 MB 331.4 kB/s eta 0:01:19\n",
      "   ------------ --------------------------- 12.3/38.1 MB 337.8 kB/s eta 0:01:17\n",
      "   ------------- -------------------------- 12.6/38.1 MB 343.5 kB/s eta 0:01:15\n",
      "   ------------- -------------------------- 12.6/38.1 MB 343.5 kB/s eta 0:01:15\n",
      "   ------------- -------------------------- 12.8/38.1 MB 349.0 kB/s eta 0:01:13\n",
      "   ------------- -------------------------- 13.1/38.1 MB 353.6 kB/s eta 0:01:11\n",
      "   ------------- -------------------------- 13.1/38.1 MB 353.6 kB/s eta 0:01:11\n",
      "   -------------- ------------------------- 13.4/38.1 MB 353.0 kB/s eta 0:01:11\n",
      "   -------------- ------------------------- 13.4/38.1 MB 353.0 kB/s eta 0:01:11\n",
      "   -------------- ------------------------- 13.6/38.1 MB 358.3 kB/s eta 0:01:09\n",
      "   -------------- ------------------------- 13.9/38.1 MB 362.4 kB/s eta 0:01:07\n",
      "   -------------- ------------------------- 14.2/38.1 MB 367.0 kB/s eta 0:01:06\n",
      "   -------------- ------------------------- 14.2/38.1 MB 367.0 kB/s eta 0:01:06\n",
      "   -------------- ------------------------- 14.2/38.1 MB 367.0 kB/s eta 0:01:06\n",
      "   -------------- ------------------------- 14.2/38.1 MB 367.0 kB/s eta 0:01:06\n",
      "   -------------- ------------------------- 14.2/38.1 MB 367.0 kB/s eta 0:01:06\n",
      "   -------------- ------------------------- 14.2/38.1 MB 367.0 kB/s eta 0:01:06\n",
      "   --------------- ------------------------ 14.4/38.1 MB 383.6 kB/s eta 0:01:02\n",
      "   --------------- ------------------------ 14.4/38.1 MB 383.6 kB/s eta 0:01:02\n",
      "   --------------- ------------------------ 14.4/38.1 MB 383.6 kB/s eta 0:01:02\n",
      "   --------------- ------------------------ 14.4/38.1 MB 383.6 kB/s eta 0:01:02\n",
      "   --------------- ------------------------ 14.4/38.1 MB 383.6 kB/s eta 0:01:02\n",
      "   --------------- ------------------------ 14.7/38.1 MB 377.7 kB/s eta 0:01:03\n",
      "   --------------- ------------------------ 14.7/38.1 MB 377.7 kB/s eta 0:01:03\n",
      "   --------------- ------------------------ 14.7/38.1 MB 377.7 kB/s eta 0:01:03\n",
      "   --------------- ------------------------ 14.9/38.1 MB 382.9 kB/s eta 0:01:01\n",
      "   --------------- ------------------------ 14.9/38.1 MB 382.9 kB/s eta 0:01:01\n",
      "   --------------- ------------------------ 15.2/38.1 MB 385.3 kB/s eta 0:01:00\n",
      "   --------------- ------------------------ 15.2/38.1 MB 385.3 kB/s eta 0:01:00\n",
      "   ---------------- ----------------------- 15.5/38.1 MB 390.2 kB/s eta 0:00:59\n",
      "   ---------------- ----------------------- 15.7/38.1 MB 395.1 kB/s eta 0:00:57\n",
      "   ---------------- ----------------------- 16.0/38.1 MB 396.7 kB/s eta 0:00:56\n",
      "   ---------------- ----------------------- 16.0/38.1 MB 396.7 kB/s eta 0:00:56\n",
      "   ----------------- ---------------------- 16.3/38.1 MB 398.4 kB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 16.3/38.1 MB 398.4 kB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 16.3/38.1 MB 398.4 kB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 16.3/38.1 MB 398.4 kB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 16.3/38.1 MB 398.4 kB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 16.3/38.1 MB 398.4 kB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 16.3/38.1 MB 398.4 kB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 16.3/38.1 MB 398.4 kB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 16.3/38.1 MB 398.4 kB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 16.3/38.1 MB 398.4 kB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 16.5/38.1 MB 400.7 kB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 16.5/38.1 MB 400.7 kB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 16.5/38.1 MB 400.7 kB/s eta 0:00:54\n",
      "   ----------------- ---------------------- 16.8/38.1 MB 403.3 kB/s eta 0:00:53\n",
      "   ----------------- ---------------------- 16.8/38.1 MB 403.3 kB/s eta 0:00:53\n",
      "   ----------------- ---------------------- 17.0/38.1 MB 407.3 kB/s eta 0:00:52\n",
      "   ----------------- ---------------------- 17.0/38.1 MB 407.3 kB/s eta 0:00:52\n",
      "   ------------------ --------------------- 17.3/38.1 MB 409.0 kB/s eta 0:00:51\n",
      "   ------------------ --------------------- 17.3/38.1 MB 409.0 kB/s eta 0:00:51\n",
      "   ------------------ --------------------- 17.6/38.1 MB 411.3 kB/s eta 0:00:51\n",
      "   ------------------ --------------------- 17.6/38.1 MB 411.3 kB/s eta 0:00:51\n",
      "   ------------------ --------------------- 17.6/38.1 MB 411.3 kB/s eta 0:00:51\n",
      "   ------------------ --------------------- 17.6/38.1 MB 411.3 kB/s eta 0:00:51\n",
      "   ------------------ --------------------- 17.6/38.1 MB 411.3 kB/s eta 0:00:51\n",
      "   ------------------ --------------------- 17.8/38.1 MB 408.3 kB/s eta 0:00:50\n",
      "   ------------------ --------------------- 17.8/38.1 MB 408.3 kB/s eta 0:00:50\n",
      "   ------------------ --------------------- 17.8/38.1 MB 408.3 kB/s eta 0:00:50\n",
      "   ------------------ --------------------- 17.8/38.1 MB 408.3 kB/s eta 0:00:50\n",
      "   ------------------ --------------------- 17.8/38.1 MB 408.3 kB/s eta 0:00:50\n",
      "   ------------------ --------------------- 17.8/38.1 MB 408.3 kB/s eta 0:00:50\n",
      "   ------------------ --------------------- 17.8/38.1 MB 408.3 kB/s eta 0:00:50\n",
      "   ------------------ --------------------- 17.8/38.1 MB 408.3 kB/s eta 0:00:50\n",
      "   ------------------ --------------------- 18.1/38.1 MB 403.4 kB/s eta 0:00:50\n",
      "   ------------------ --------------------- 18.1/38.1 MB 403.4 kB/s eta 0:00:50\n",
      "   ------------------ --------------------- 18.1/38.1 MB 403.4 kB/s eta 0:00:50\n",
      "   ------------------ --------------------- 18.1/38.1 MB 403.4 kB/s eta 0:00:50\n",
      "   ------------------- -------------------- 18.4/38.1 MB 414.7 kB/s eta 0:00:48\n",
      "   ------------------- -------------------- 18.4/38.1 MB 414.7 kB/s eta 0:00:48\n",
      "   ------------------- -------------------- 18.6/38.1 MB 414.8 kB/s eta 0:00:48\n",
      "   ------------------- -------------------- 18.6/38.1 MB 414.8 kB/s eta 0:00:48\n",
      "   ------------------- -------------------- 18.9/38.1 MB 417.7 kB/s eta 0:00:47\n",
      "   -------------------- ------------------- 19.1/38.1 MB 422.5 kB/s eta 0:00:45\n",
      "   -------------------- ------------------- 19.1/38.1 MB 422.5 kB/s eta 0:00:45\n",
      "   -------------------- ------------------- 19.4/38.1 MB 424.7 kB/s eta 0:00:45\n",
      "   -------------------- ------------------- 19.7/38.1 MB 428.6 kB/s eta 0:00:44\n",
      "   -------------------- ------------------- 19.7/38.1 MB 428.6 kB/s eta 0:00:44\n",
      "   -------------------- ------------------- 19.9/38.1 MB 430.0 kB/s eta 0:00:43\n",
      "   --------------------- ------------------ 20.2/38.1 MB 433.1 kB/s eta 0:00:42\n",
      "   --------------------- ------------------ 20.2/38.1 MB 433.1 kB/s eta 0:00:42\n",
      "   --------------------- ------------------ 20.2/38.1 MB 433.1 kB/s eta 0:00:42\n",
      "   --------------------- ------------------ 20.4/38.1 MB 434.7 kB/s eta 0:00:41\n",
      "   --------------------- ------------------ 20.4/38.1 MB 434.7 kB/s eta 0:00:41\n",
      "   --------------------- ------------------ 20.4/38.1 MB 434.7 kB/s eta 0:00:41\n",
      "   --------------------- ------------------ 20.4/38.1 MB 434.7 kB/s eta 0:00:41\n",
      "   --------------------- ------------------ 20.7/38.1 MB 430.0 kB/s eta 0:00:41\n",
      "   --------------------- ------------------ 20.7/38.1 MB 430.0 kB/s eta 0:00:41\n",
      "   --------------------- ------------------ 20.7/38.1 MB 430.0 kB/s eta 0:00:41\n",
      "   --------------------- ------------------ 21.0/38.1 MB 436.6 kB/s eta 0:00:40\n",
      "   --------------------- ------------------ 21.0/38.1 MB 436.6 kB/s eta 0:00:40\n",
      "   --------------------- ------------------ 21.0/38.1 MB 436.6 kB/s eta 0:00:40\n",
      "   ---------------------- ----------------- 21.2/38.1 MB 432.7 kB/s eta 0:00:40\n",
      "   ---------------------- ----------------- 21.2/38.1 MB 432.7 kB/s eta 0:00:40\n",
      "   ---------------------- ----------------- 21.5/38.1 MB 434.0 kB/s eta 0:00:39\n",
      "   ---------------------- ----------------- 21.5/38.1 MB 434.0 kB/s eta 0:00:39\n",
      "   ---------------------- ----------------- 21.8/38.1 MB 438.0 kB/s eta 0:00:38\n",
      "   ---------------------- ----------------- 21.8/38.1 MB 438.0 kB/s eta 0:00:38\n",
      "   ----------------------- ---------------- 22.0/38.1 MB 441.5 kB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 22.0/38.1 MB 441.5 kB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 22.3/38.1 MB 441.3 kB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 22.3/38.1 MB 441.3 kB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 22.5/38.1 MB 439.9 kB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 22.5/38.1 MB 439.9 kB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 22.5/38.1 MB 439.9 kB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 22.5/38.1 MB 439.9 kB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 22.5/38.1 MB 439.9 kB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 22.5/38.1 MB 439.9 kB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 22.8/38.1 MB 449.1 kB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 22.8/38.1 MB 449.1 kB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 22.8/38.1 MB 449.1 kB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 22.8/38.1 MB 449.1 kB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 22.8/38.1 MB 449.1 kB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 22.8/38.1 MB 449.1 kB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 22.8/38.1 MB 449.1 kB/s eta 0:00:35\n",
      "   ----------------------- ---------------- 22.8/38.1 MB 449.1 kB/s eta 0:00:35\n",
      "   ------------------------ --------------- 23.1/38.1 MB 435.7 kB/s eta 0:00:35\n",
      "   ------------------------ --------------- 23.1/38.1 MB 435.7 kB/s eta 0:00:35\n",
      "   ------------------------ --------------- 23.1/38.1 MB 435.7 kB/s eta 0:00:35\n",
      "   ------------------------ --------------- 23.3/38.1 MB 439.6 kB/s eta 0:00:34\n",
      "   ------------------------ --------------- 23.3/38.1 MB 439.6 kB/s eta 0:00:34\n",
      "   ------------------------ --------------- 23.6/38.1 MB 441.5 kB/s eta 0:00:33\n",
      "   ------------------------ --------------- 23.6/38.1 MB 441.5 kB/s eta 0:00:33\n",
      "   ------------------------ --------------- 23.6/38.1 MB 441.5 kB/s eta 0:00:33\n",
      "   ------------------------- -------------- 23.9/38.1 MB 431.1 kB/s eta 0:00:34\n",
      "   ------------------------- -------------- 23.9/38.1 MB 431.1 kB/s eta 0:00:34\n",
      "   ------------------------- -------------- 23.9/38.1 MB 431.1 kB/s eta 0:00:34\n",
      "   ------------------------- -------------- 24.1/38.1 MB 430.0 kB/s eta 0:00:33\n",
      "   ------------------------- -------------- 24.1/38.1 MB 430.0 kB/s eta 0:00:33\n",
      "   ------------------------- -------------- 24.1/38.1 MB 430.0 kB/s eta 0:00:33\n",
      "   ------------------------- -------------- 24.1/38.1 MB 430.0 kB/s eta 0:00:33\n",
      "   ------------------------- -------------- 24.1/38.1 MB 430.0 kB/s eta 0:00:33\n",
      "   ------------------------- -------------- 24.1/38.1 MB 430.0 kB/s eta 0:00:33\n",
      "   ------------------------- -------------- 24.1/38.1 MB 430.0 kB/s eta 0:00:33\n",
      "   ------------------------- -------------- 24.1/38.1 MB 430.0 kB/s eta 0:00:33\n",
      "   ------------------------- -------------- 24.4/38.1 MB 425.9 kB/s eta 0:00:33\n",
      "   ------------------------- -------------- 24.4/38.1 MB 425.9 kB/s eta 0:00:33\n",
      "   ------------------------- -------------- 24.4/38.1 MB 425.9 kB/s eta 0:00:33\n",
      "   ------------------------- -------------- 24.4/38.1 MB 425.9 kB/s eta 0:00:33\n",
      "   ------------------------- -------------- 24.4/38.1 MB 425.9 kB/s eta 0:00:33\n",
      "   ------------------------- -------------- 24.6/38.1 MB 404.5 kB/s eta 0:00:34\n",
      "   ------------------------- -------------- 24.6/38.1 MB 404.5 kB/s eta 0:00:34\n",
      "   ------------------------- -------------- 24.6/38.1 MB 404.5 kB/s eta 0:00:34\n",
      "   -------------------------- ------------- 24.9/38.1 MB 396.1 kB/s eta 0:00:34\n",
      "   -------------------------- ------------- 25.2/38.1 MB 397.4 kB/s eta 0:00:33\n",
      "   -------------------------- ------------- 25.2/38.1 MB 397.4 kB/s eta 0:00:33\n",
      "   -------------------------- ------------- 25.4/38.1 MB 396.5 kB/s eta 0:00:33\n",
      "   -------------------------- ------------- 25.7/38.1 MB 395.7 kB/s eta 0:00:32\n",
      "   --------------------------- ------------ 26.0/38.1 MB 397.3 kB/s eta 0:00:31\n",
      "   --------------------------- ------------ 26.2/38.1 MB 404.1 kB/s eta 0:00:30\n",
      "   --------------------------- ------------ 26.2/38.1 MB 404.1 kB/s eta 0:00:30\n",
      "   --------------------------- ------------ 26.5/38.1 MB 414.2 kB/s eta 0:00:29\n",
      "   --------------------------- ------------ 26.5/38.1 MB 414.2 kB/s eta 0:00:29\n",
      "   --------------------------- ------------ 26.5/38.1 MB 414.2 kB/s eta 0:00:29\n",
      "   --------------------------- ------------ 26.5/38.1 MB 414.2 kB/s eta 0:00:29\n",
      "   ---------------------------- ----------- 26.7/38.1 MB 417.2 kB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 26.7/38.1 MB 417.2 kB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 26.7/38.1 MB 417.2 kB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 26.7/38.1 MB 417.2 kB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 26.7/38.1 MB 417.2 kB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 26.7/38.1 MB 417.2 kB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 27.0/38.1 MB 407.9 kB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 27.0/38.1 MB 407.9 kB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 27.0/38.1 MB 407.9 kB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 27.0/38.1 MB 407.9 kB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 27.0/38.1 MB 407.9 kB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 27.3/38.1 MB 394.5 kB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 27.3/38.1 MB 394.5 kB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 27.3/38.1 MB 394.5 kB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 27.5/38.1 MB 387.3 kB/s eta 0:00:28\n",
      "   ----------------------------- ---------- 28.0/38.1 MB 395.7 kB/s eta 0:00:26\n",
      "   ----------------------------- ---------- 28.3/38.1 MB 402.4 kB/s eta 0:00:25\n",
      "   ------------------------------ --------- 28.8/38.1 MB 439.3 kB/s eta 0:00:22\n",
      "   ------------------------------ --------- 28.8/38.1 MB 439.3 kB/s eta 0:00:22\n",
      "   ------------------------------ --------- 28.8/38.1 MB 439.3 kB/s eta 0:00:22\n",
      "   ------------------------------ --------- 29.1/38.1 MB 441.8 kB/s eta 0:00:21\n",
      "   ------------------------------ --------- 29.1/38.1 MB 441.8 kB/s eta 0:00:21\n",
      "   ------------------------------ --------- 29.1/38.1 MB 441.8 kB/s eta 0:00:21\n",
      "   ------------------------------ --------- 29.4/38.1 MB 441.0 kB/s eta 0:00:20\n",
      "   ------------------------------ --------- 29.4/38.1 MB 441.0 kB/s eta 0:00:20\n",
      "   ------------------------------ --------- 29.4/38.1 MB 441.0 kB/s eta 0:00:20\n",
      "   ------------------------------ --------- 29.4/38.1 MB 441.0 kB/s eta 0:00:20\n",
      "   ------------------------------ --------- 29.4/38.1 MB 441.0 kB/s eta 0:00:20\n",
      "   ------------------------------- -------- 29.6/38.1 MB 432.0 kB/s eta 0:00:20\n",
      "   ------------------------------- -------- 29.6/38.1 MB 432.0 kB/s eta 0:00:20\n",
      "   ------------------------------- -------- 29.6/38.1 MB 432.0 kB/s eta 0:00:20\n",
      "   ------------------------------- -------- 29.9/38.1 MB 430.2 kB/s eta 0:00:20\n",
      "   ------------------------------- -------- 30.1/38.1 MB 433.8 kB/s eta 0:00:19\n",
      "   ------------------------------- -------- 30.1/38.1 MB 433.8 kB/s eta 0:00:19\n",
      "   ------------------------------- -------- 30.4/38.1 MB 433.1 kB/s eta 0:00:18\n",
      "   ------------------------------- -------- 30.4/38.1 MB 433.1 kB/s eta 0:00:18\n",
      "   -------------------------------- ------- 30.7/38.1 MB 440.8 kB/s eta 0:00:17\n",
      "   -------------------------------- ------- 30.9/38.1 MB 445.0 kB/s eta 0:00:17\n",
      "   -------------------------------- ------- 30.9/38.1 MB 445.0 kB/s eta 0:00:17\n",
      "   -------------------------------- ------- 31.2/38.1 MB 449.4 kB/s eta 0:00:16\n",
      "   -------------------------------- ------- 31.5/38.1 MB 454.6 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 31.5/38.1 MB 454.6 kB/s eta 0:00:15\n",
      "   --------------------------------- ------ 31.7/38.1 MB 475.2 kB/s eta 0:00:14\n",
      "   --------------------------------- ------ 31.7/38.1 MB 475.2 kB/s eta 0:00:14\n",
      "   --------------------------------- ------ 31.7/38.1 MB 475.2 kB/s eta 0:00:14\n",
      "   --------------------------------- ------ 31.7/38.1 MB 475.2 kB/s eta 0:00:14\n",
      "   --------------------------------- ------ 31.7/38.1 MB 475.2 kB/s eta 0:00:14\n",
      "   --------------------------------- ------ 31.7/38.1 MB 475.2 kB/s eta 0:00:14\n",
      "   --------------------------------- ------ 31.7/38.1 MB 475.2 kB/s eta 0:00:14\n",
      "   --------------------------------- ------ 31.7/38.1 MB 475.2 kB/s eta 0:00:14\n",
      "   --------------------------------- ------ 32.0/38.1 MB 462.3 kB/s eta 0:00:14\n",
      "   --------------------------------- ------ 32.0/38.1 MB 462.3 kB/s eta 0:00:14\n",
      "   --------------------------------- ------ 32.2/38.1 MB 463.4 kB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 32.5/38.1 MB 468.5 kB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 32.5/38.1 MB 468.5 kB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 32.8/38.1 MB 468.2 kB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 32.8/38.1 MB 468.2 kB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 33.0/38.1 MB 466.0 kB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 33.0/38.1 MB 466.0 kB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 33.3/38.1 MB 464.6 kB/s eta 0:00:11\n",
      "   ----------------------------------- ---- 33.6/38.1 MB 465.5 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 33.8/38.1 MB 467.0 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 34.1/38.1 MB 472.6 kB/s eta 0:00:09\n",
      "   ------------------------------------ --- 34.3/38.1 MB 474.1 kB/s eta 0:00:09\n",
      "   ------------------------------------ --- 34.3/38.1 MB 474.1 kB/s eta 0:00:09\n",
      "   ------------------------------------ --- 34.6/38.1 MB 478.6 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 34.6/38.1 MB 478.6 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 34.6/38.1 MB 478.6 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 34.6/38.1 MB 478.6 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 34.6/38.1 MB 478.6 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 34.6/38.1 MB 478.6 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 34.6/38.1 MB 478.6 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 34.9/38.1 MB 468.2 kB/s eta 0:00:07\n",
      "   ------------------------------------ --- 34.9/38.1 MB 468.2 kB/s eta 0:00:07\n",
      "   ------------------------------------ --- 34.9/38.1 MB 468.2 kB/s eta 0:00:07\n",
      "   ------------------------------------ --- 34.9/38.1 MB 468.2 kB/s eta 0:00:07\n",
      "   ------------------------------------ --- 35.1/38.1 MB 466.3 kB/s eta 0:00:07\n",
      "   ------------------------------------ --- 35.1/38.1 MB 466.3 kB/s eta 0:00:07\n",
      "   ------------------------------------ --- 35.1/38.1 MB 466.3 kB/s eta 0:00:07\n",
      "   ------------------------------------- -- 35.4/38.1 MB 458.0 kB/s eta 0:00:07\n",
      "   ------------------------------------- -- 35.4/38.1 MB 458.0 kB/s eta 0:00:07\n",
      "   ------------------------------------- -- 35.7/38.1 MB 459.4 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 35.9/38.1 MB 460.9 kB/s eta 0:00:05\n",
      "   ------------------------------------- -- 35.9/38.1 MB 460.9 kB/s eta 0:00:05\n",
      "   ------------------------------------- -- 36.2/38.1 MB 464.3 kB/s eta 0:00:05\n",
      "   -------------------------------------- - 36.4/38.1 MB 466.8 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 36.7/38.1 MB 472.9 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 37.0/38.1 MB 490.8 kB/s eta 0:00:03\n",
      "   -------------------------------------- - 37.0/38.1 MB 490.8 kB/s eta 0:00:03\n",
      "   -------------------------------------- - 37.0/38.1 MB 490.8 kB/s eta 0:00:03\n",
      "   -------------------------------------- - 37.0/38.1 MB 490.8 kB/s eta 0:00:03\n",
      "   ---------------------------------------  37.2/38.1 MB 484.1 kB/s eta 0:00:02\n",
      "   ---------------------------------------  37.2/38.1 MB 484.1 kB/s eta 0:00:02\n",
      "   ---------------------------------------  37.5/38.1 MB 505.3 kB/s eta 0:00:02\n",
      "   ---------------------------------------  37.5/38.1 MB 505.3 kB/s eta 0:00:02\n",
      "   ---------------------------------------  37.5/38.1 MB 505.3 kB/s eta 0:00:02\n",
      "   ---------------------------------------  37.7/38.1 MB 503.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------  37.7/38.1 MB 503.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------  38.0/38.1 MB 505.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.1/38.1 MB 505.2 kB/s eta 0:00:00\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Building wheels for collected packages: argbind, julius, randomname\n",
      "  Building wheel for argbind (pyproject.toml): started\n",
      "  Building wheel for argbind (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for argbind: filename=argbind-0.3.9-py2.py3-none-any.whl size=11896 sha256=8418e82a0141b70951b4403fe8bd84e21eb9fd77bea0ba8aa24e60797bff9c18\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\eb\\33\\cb\\c5e898b01c657604d61ef1462002dee37ed67b4b05b871dc45\n",
      "  Building wheel for julius (pyproject.toml): started\n",
      "  Building wheel for julius (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=22017 sha256=3e651bcc42fb754d893a67dc3aa052c21f66704faba51cd74aa7a901b0d05c09\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\de\\c1\\ca\\544dafe48401e8e2e17064dfe465a390fca9e8720ffa12e744\n",
      "  Building wheel for randomname (pyproject.toml): started\n",
      "  Building wheel for randomname (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for randomname: filename=randomname-0.2.1-py3-none-any.whl size=89313 sha256=3678605e378ed71a281e333fe65d294bb5156d3c73014a90b4a8608455bf23f6\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\05\\6e\\37\\1db72aaa77a57f2dcbc97fd96a47f14091130a1dde562124c0\n",
      "Successfully built argbind julius randomname\n",
      "Installing collected packages: werkzeug, tqdm, termcolor, tensorboard-data-server, soxr, safetensors, regex, protobuf, msgpack, mdurl, markdown2, markdown, llvmlite, lazy_loader, importlib-resources, grpcio, future, flatten-dict, ffmpy, einops, docstring-parser, audioread, absl-py, tensorboard, soundfile, pystoi, pyloudnorm, pooch, numba, markdown-it-py, huggingface-hub, fire, argbind, torchaudio, tokenizers, rich, randomname, librosa, julius, transformers, torch-stoi, descript-audiotools, descript-audio-codec\n",
      "Successfully installed absl-py-2.3.1 argbind-0.3.9 audioread-3.1.0 descript-audio-codec-1.0.0 descript-audiotools-0.7.2 docstring-parser-0.17.0 einops-0.8.1 ffmpy-1.0.0 fire-0.7.1 flatten-dict-0.4.2 future-1.0.0 grpcio-1.76.0 huggingface-hub-0.36.0 importlib-resources-6.5.2 julius-0.2.7 lazy_loader-0.4 librosa-0.11.0 llvmlite-0.46.0 markdown-3.10 markdown-it-py-4.0.0 markdown2-2.5.4 mdurl-0.1.2 msgpack-1.1.2 numba-0.63.1 pooch-1.8.2 protobuf-3.19.6 pyloudnorm-0.1.1 pystoi-0.4.1 randomname-0.2.1 regex-2025.11.3 rich-14.2.0 safetensors-0.7.0 soundfile-0.13.1 soxr-1.0.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 termcolor-3.2.0 tokenizers-0.22.1 torch-stoi-0.2.3 torchaudio-2.9.1 tqdm-4.67.1 transformers-4.57.3 werkzeug-3.1.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Core dependencies\n",
    "#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "!pip install torchaudio transformers einops tqdm descript-audio-codec\n",
    "#audiotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c97d916-76f7-4190-9f75-0157220a915d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting descript-audio-codec\n",
      "  Using cached descript_audio_codec-1.0.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting argbind>=0.3.7 (from descript-audio-codec)\n",
      "  Downloading argbind-0.3.9.tar.gz (17 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting descript-audiotools>=0.7.2 (from descript-audio-codec)\n",
      "  Downloading descript_audiotools-0.7.2-py2.py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: einops in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from descript-audio-codec) (0.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from descript-audio-codec) (1.26.4)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from descript-audio-codec) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from descript-audio-codec) (2.5.1+cu121)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from descript-audio-codec) (4.67.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from argbind>=0.3.7->descript-audio-codec) (6.0.3)\n",
      "Collecting docstring-parser (from argbind>=0.3.7->descript-audio-codec)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: soundfile in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from descript-audiotools>=0.7.2->descript-audio-codec) (0.13.1)\n",
      "Collecting pyloudnorm (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading pyloudnorm-0.1.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting importlib-resources (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from descript-audiotools>=0.7.2->descript-audio-codec) (1.16.2)\n",
      "Collecting julius (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: ffmpy in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from descript-audiotools>=0.7.2->descript-audio-codec) (1.0.0)\n",
      "Requirement already satisfied: ipython in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from descript-audiotools>=0.7.2->descript-audio-codec) (9.6.0)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from descript-audiotools>=0.7.2->descript-audio-codec) (14.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from descript-audiotools>=0.7.2->descript-audio-codec) (3.10.7)\n",
      "Requirement already satisfied: librosa in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from descript-audiotools>=0.7.2->descript-audio-codec) (0.11.0)\n",
      "Collecting pystoi (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading pystoi-0.4.1-py2.py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting torch-stoi (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading torch_stoi-0.2.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting flatten-dict (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading flatten_dict-0.4.2-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting markdown2 (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading markdown2-2.5.4-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting randomname (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading randomname-0.2.1.tar.gz (64 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting protobuf<3.20,>=3.9.2 (from descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading protobuf-3.19.6-py2.py3-none-any.whl.metadata (828 bytes)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from descript-audiotools>=0.7.2->descript-audio-codec) (2.20.0)\n",
      "Requirement already satisfied: six<2.0,>=1.12 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flatten-dict->descript-audiotools>=0.7.2->descript-audio-codec) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython->descript-audiotools>=0.7.2->descript-audio-codec) (0.4.4)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython->descript-audiotools>=0.7.2->descript-audio-codec) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython->descript-audiotools>=0.7.2->descript-audio-codec) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython->descript-audiotools>=0.7.2->descript-audio-codec) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython->descript-audiotools>=0.7.2->descript-audio-codec) (0.2.1)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython->descript-audiotools>=0.7.2->descript-audio-codec) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython->descript-audiotools>=0.7.2->descript-audio-codec) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython->descript-audiotools>=0.7.2->descript-audio-codec) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython->descript-audiotools>=0.7.2->descript-audio-codec) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython->descript-audiotools>=0.7.2->descript-audio-codec) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jedi>=0.16->ipython->descript-audiotools>=0.7.2->descript-audio-codec) (0.8.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->descript-audio-codec) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->descript-audio-codec) (4.15.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->descript-audio-codec) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->descript-audio-codec) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->descript-audio-codec) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->descript-audio-codec) (80.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->descript-audio-codec) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch->descript-audio-codec) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch->descript-audio-codec) (3.0.3)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa->descript-audiotools>=0.7.2->descript-audio-codec) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa->descript-audiotools>=0.7.2->descript-audio-codec) (0.62.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa->descript-audiotools>=0.7.2->descript-audio-codec) (1.7.2)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa->descript-audiotools>=0.7.2->descript-audio-codec) (1.5.2)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa->descript-audiotools>=0.7.2->descript-audio-codec) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa->descript-audiotools>=0.7.2->descript-audio-codec) (1.0.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa->descript-audiotools>=0.7.2->descript-audio-codec) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from librosa->descript-audiotools>=0.7.2->descript-audio-codec) (1.1.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lazy_loader>=0.1->librosa->descript-audiotools>=0.7.2->descript-audio-codec) (25.0)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from numba>=0.51.0->librosa->descript-audiotools>=0.7.2->descript-audio-codec) (0.45.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pooch>=1.1->librosa->descript-audiotools>=0.7.2->descript-audio-codec) (4.5.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pooch>=1.1->librosa->descript-audiotools>=0.7.2->descript-audio-codec) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa->descript-audiotools>=0.7.2->descript-audio-codec) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa->descript-audiotools>=0.7.2->descript-audio-codec) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa->descript-audiotools>=0.7.2->descript-audio-codec) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa->descript-audiotools>=0.7.2->descript-audio-codec) (2025.10.5)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=1.1.0->librosa->descript-audiotools>=0.7.2->descript-audio-codec) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from soundfile->descript-audiotools>=0.7.2->descript-audio-codec) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.0->soundfile->descript-audiotools>=0.7.2->descript-audio-codec) (2.23)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->descript-audiotools>=0.7.2->descript-audio-codec) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->descript-audiotools>=0.7.2->descript-audio-codec) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->descript-audiotools>=0.7.2->descript-audio-codec) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->descript-audiotools>=0.7.2->descript-audio-codec) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->descript-audiotools>=0.7.2->descript-audio-codec) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->descript-audiotools>=0.7.2->descript-audio-codec) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->descript-audiotools>=0.7.2->descript-audio-codec) (2.9.0.post0)\n",
      "Collecting future>=0.16.0 (from pyloudnorm->descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting fire (from randomname->descript-audiotools>=0.7.2->descript-audio-codec)\n",
      "  Using cached fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: termcolor in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fire->randomname->descript-audiotools>=0.7.2->descript-audio-codec) (3.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->descript-audiotools>=0.7.2->descript-audio-codec) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->descript-audiotools>=0.7.2->descript-audio-codec) (0.1.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stack_data->ipython->descript-audiotools>=0.7.2->descript-audio-codec) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stack_data->ipython->descript-audiotools>=0.7.2->descript-audio-codec) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stack_data->ipython->descript-audiotools>=0.7.2->descript-audio-codec) (0.2.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard->descript-audiotools>=0.7.2->descript-audio-codec) (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard->descript-audiotools>=0.7.2->descript-audio-codec) (1.76.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard->descript-audiotools>=0.7.2->descript-audio-codec) (3.9)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard->descript-audiotools>=0.7.2->descript-audio-codec) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard->descript-audiotools>=0.7.2->descript-audio-codec) (3.1.3)\n",
      "Downloading descript_audio_codec-1.0.0-py3-none-any.whl (26 kB)\n",
      "Downloading descript_audiotools-0.7.2-py2.py3-none-any.whl (106 kB)\n",
      "Downloading protobuf-3.19.6-py2.py3-none-any.whl (162 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading flatten_dict-0.4.2-py2.py3-none-any.whl (9.7 kB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading markdown2-2.5.4-py3-none-any.whl (49 kB)\n",
      "Downloading pyloudnorm-0.1.1-py3-none-any.whl (9.6 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Downloading pystoi-0.4.1-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached fire-0.7.1-py3-none-any.whl (115 kB)\n",
      "Downloading torch_stoi-0.2.3-py3-none-any.whl (8.1 kB)\n",
      "Building wheels for collected packages: argbind, julius, randomname\n",
      "  Building wheel for argbind (pyproject.toml): started\n",
      "  Building wheel for argbind (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for argbind: filename=argbind-0.3.9-py2.py3-none-any.whl size=11896 sha256=c0578537454cc2e67847e087da9aea6ead5537e8fc84c2955723743d0b3b822e\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\eb\\33\\cb\\c5e898b01c657604d61ef1462002dee37ed67b4b05b871dc45\n",
      "  Building wheel for julius (pyproject.toml): started\n",
      "  Building wheel for julius (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=22017 sha256=2d924306cf804f5d409961173fca17ad58e1ee21d4b15e58ddfca67ba2df8e5b\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\de\\c1\\ca\\544dafe48401e8e2e17064dfe465a390fca9e8720ffa12e744\n",
      "  Building wheel for randomname (pyproject.toml): started\n",
      "  Building wheel for randomname (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for randomname: filename=randomname-0.2.1-py3-none-any.whl size=89313 sha256=ae09ca85a6b768f7bd46a456a9c6a9565dc2ca77f7ceae32aae7aa2d8a41b7a6\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\05\\6e\\37\\1db72aaa77a57f2dcbc97fd96a47f14091130a1dde562124c0\n",
      "Successfully built argbind julius randomname\n",
      "Installing collected packages: protobuf, markdown2, importlib-resources, future, flatten-dict, fire, docstring-parser, randomname, pystoi, pyloudnorm, argbind, julius, torch-stoi, descript-audiotools, descript-audio-codec\n",
      "\n",
      "  Attempting uninstall: protobuf\n",
      "\n",
      "    Found existing installation: protobuf 6.33.0\n",
      "\n",
      "    Uninstalling protobuf-6.33.0:\n",
      "\n",
      "      Successfully uninstalled protobuf-6.33.0\n",
      "\n",
      "   ----------------------------------------  0/15 [protobuf]\n",
      "   ----------------------------------------  0/15 [protobuf]\n",
      "   ----- ----------------------------------  2/15 [importlib-resources]\n",
      "   -------- -------------------------------  3/15 [future]\n",
      "   -------- -------------------------------  3/15 [future]\n",
      "   -------- -------------------------------  3/15 [future]\n",
      "   -------- -------------------------------  3/15 [future]\n",
      "   -------- -------------------------------  3/15 [future]\n",
      "   -------- -------------------------------  3/15 [future]\n",
      "   -------- -------------------------------  3/15 [future]\n",
      "   -------- -------------------------------  3/15 [future]\n",
      "   ------------- --------------------------  5/15 [fire]\n",
      "   ------------- --------------------------  5/15 [fire]\n",
      "   ---------------- -----------------------  6/15 [docstring-parser]\n",
      "   ------------------ ---------------------  7/15 [randomname]\n",
      "   --------------------- ------------------  8/15 [pystoi]\n",
      "   -------------------------------- ------- 12/15 [torch-stoi]\n",
      "   ---------------------------------- ----- 13/15 [descript-audiotools]\n",
      "   ------------------------------------- -- 14/15 [descript-audio-codec]\n",
      "   ---------------------------------------- 15/15 [descript-audio-codec]\n",
      "\n",
      "Successfully installed argbind-0.3.9 descript-audio-codec-1.0.0 descript-audiotools-0.7.2 docstring-parser-0.17.0 fire-0.7.1 flatten-dict-0.4.2 future-1.0.0 importlib-resources-6.5.2 julius-0.2.7 markdown2-2.5.4 protobuf-3.19.6 pyloudnorm-0.1.1 pystoi-0.4.1 randomname-0.2.1 torch-stoi-0.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "databricks-sdk 0.70.0 requires protobuf<7.0,>=4.21.0, but you have protobuf 3.19.6 which is incompatible.\n",
      "opentelemetry-proto 1.38.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.19.6 which is incompatible.\n",
      "ray 2.52.1 requires protobuf>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
      "tensorflow 2.20.0 requires protobuf>=5.28.0, but you have protobuf 3.19.6 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/descriptinc/audiotools\n",
      "  Cloning https://github.com/descriptinc/audiotools to c:\\users\\user\\appdata\\local\\temp\\pip-req-build-5_d7i_qg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/descriptinc/audiotools 'C:\\Users\\user\\AppData\\Local\\Temp\\pip-req-build-5_d7i_qg'\n",
      "  fatal: unable to access 'https://github.com/descriptinc/audiotools/': Could not resolve host: github.com\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  git clone --filter=blob:none --quiet https://github.com/descriptinc/audiotools 'C:\\Users\\user\\AppData\\Local\\Temp\\pip-req-build-5_d7i_qg' did not run successfully.\n",
      "  exit code: 128\n",
      "  \n",
      "  No available output.\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "ERROR: Failed to build 'git+https://github.com/descriptinc/audiotools' when git clone --filter=blob:none --quiet https://github.com/descriptinc/audiotools 'c:\\users\\user\\appdata\\local\\temp\\pip-req-build-5_d7i_qg'\n"
     ]
    }
   ],
   "source": [
    "!pip install --retries 10 --timeout 30 descript-audio-codec\n",
    "!pip install --retries 10 --timeout 30 git+https://github.com/descriptinc/audiotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48dd4934-8145-453f-b006-3b164abe0d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchcodec\n",
      "  Downloading torchcodec-0.9.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Downloading torchcodec-0.9.1-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 31.0 MB/s eta 0:00:00\n",
      "Installing collected packages: torchcodec\n",
      "Successfully installed torchcodec-0.9.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torchcodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc4de9-e0cc-40af-9e54-61cd9184b346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Processing c:\\users\\user\\downloads\\protobuf-5.28.3-cp310-abi3-win_amd64.whl\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "Successfully installed protobuf-5.28.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "descript-audiotools 0.7.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 5.28.3 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# In notebook:\n",
    "!pip install \"C:/Users/user/Downloads/protobuf-5.28.3-cp310-abi3-win_amd64.whl\" --force-reinstal\n",
    "# manual download of protobuf because of DNS issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c46124-1a6a-4d59-894c-92e9d55fd70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DAC model found! You can train!\n",
      "   Location: C:/Users/user/Downloads/weights_44khz_16kbps.pth\n",
      "   Size: 245.08 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dac_model_path = \"C:/Users/user/Downloads/weights_44khz_16kbps.pth\"\n",
    "# manual download of DAC because of DNS issues from official github repo releases \n",
    "\n",
    "if os.path.exists(dac_model_path):\n",
    "    print(\"✅ DAC model found! You can train!\")\n",
    "    print(f\"   Location: {dac_model_path}\")\n",
    "    file_size = os.path.getsize(dac_model_path) / (1024 * 1024)\n",
    "    print(f\"   Size: {file_size:.2f} MB\")\n",
    "else:\n",
    "    print(\"❌ DAC model NOT found!\")\n",
    "    print(f\"   Expected location: {dac_model_path}\")\n",
    "    print(\"\\n📥 You need to download it first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c269a-ddfd-4507-904c-5f3fb4ea783e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: soundfile in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (0.13.1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from soundfile) (2.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from soundfile) (2.3.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from cffi>=1.0->soundfile) (2.23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile\n",
    "# use soundfile instead to avoid audiotools issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cc5674-8aca-41fc-ae75-07624bd30a92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ soundfile available\n",
      "✓ DAC library imported successfully\n",
      "============================================================\n",
      "DAC-VAE AUDIO EFFECT GENERATOR (No AudioTools)\n",
      "============================================================\n",
      "Device: cuda\n",
      "Sample Rate: 44100 Hz\n",
      "Max Length: 5.0 seconds\n",
      "Batch Size: 4 x 4 = 16\n",
      "============================================================\n",
      "\n",
      "Loading DAC model...\n",
      "✓ Loading from: C:/Users/user/Downloads/weights_44khz_16kbps.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\utils\\weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ DAC model loaded and frozen\n",
      "✓ DAC Latent Channels: 128\n",
      "✓ Time Reduction Factor: 512x\n",
      "\n",
      "============================================================\n",
      "LOADING DATASET\n",
      "============================================================\n",
      "Original dataset: 5000 samples\n",
      "\n",
      "Validating files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████| 5000/5000 [00:01<00:00, 3309.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Valid samples: 5000\n",
      "\n",
      "Dataset splits:\n",
      "  Train:      3500 samples (70.0%)\n",
      "  Validation: 750 samples (15.0%)\n",
      "  Test:       750 samples (15.0%)\n",
      "\n",
      "Loading tokenizer...\n",
      "✓ Tokenizer loaded\n",
      "\n",
      "============================================================\n",
      "CREATING DATALOADERS\n",
      "============================================================\n",
      "Batches per epoch:\n",
      "  Train: 875 batches\n",
      "  Val:   188 batches\n",
      "  Test:  188 batches\n",
      "\n",
      "============================================================\n",
      "INITIALIZING MODEL\n",
      "============================================================\n",
      "Text encoder: FROZEN ❄️\n",
      "Total parameters: 188,877,378\n",
      "Trainable parameters: 15,181,888\n",
      "Frozen parameters: 173,695,490\n",
      "UNet channels: [64, 128, 256, 512]\n",
      "Latent channels: 128\n",
      "\n",
      "============================================================\n",
      "TRAINING SETUP\n",
      "============================================================\n",
      "Optimizer: AdamW\n",
      "Learning rate: 2e-05\n",
      "Scheduler: CosineAnnealingLR\n",
      "Loss: L1 (audio) + MSE (latent)\n",
      "Mixed precision: True\n",
      "\n",
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "Total epochs: 100\n",
      "Steps per epoch: 875\n",
      "Validation every epoch\n",
      "============================================================\n",
      "\n",
      "Loading checkpoint...\n",
      "✓ Resumed from epoch 100\n",
      "\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "TESTING BEST MODEL\n",
      "============================================================\n",
      "\n",
      "Loaded best model from epoch 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation 101/100: 100%|█| 188/188 [03:13<00:00,  1.03s/it, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL TEST RESULTS\n",
      "============================================================\n",
      "Test Loss:  1.264591\n",
      "  Audio Loss:  0.110320\n",
      "  Latent Loss: 9.159253\n",
      "============================================================\n",
      "\n",
      "Generating training curves...\n",
      "✓ Plot saved to: C:/zahra/EchoMind/data/result/training_curves.png\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/zahra/EchoMind/data/result_DAC/training_summary.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m--------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1092\u001b[39m\n\u001b[32m   1056\u001b[39m summary = {\n\u001b[32m   1057\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m   1058\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtotal_samples\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(df),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1088\u001b[39m     }\n\u001b[32m   1089\u001b[39m }\n\u001b[32m   1091\u001b[39m summary_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg.base_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/result_DAC/training_summary.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1092\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msummary_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m   1093\u001b[39m     json.dump(summary, f, indent=\u001b[32m2\u001b[39m)\n\u001b[32m   1095\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✓ Summary saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msummary_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:344\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    338\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    339\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    342\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:/zahra/EchoMind/data/result_DAC/training_summary.json'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Production-Ready Audio Effect Generator using DAC-VAE (No AudioTools)\n",
    "NO AUDIOTOOLS DEPENDENCY - Uses DAC encoder/decoder directly!\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from einops import rearrange\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torchaudio\n",
    "import soundfile  # This import confirms it's installed\n",
    "print(\"✓ soundfile available\")\n",
    "\n",
    "# DAC import (NO audiotools needed!)\n",
    "try:\n",
    "    import dac\n",
    "    print(\"✓ DAC library imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"❌ DAC not installed. Run: pip install descript-audio-codec\")\n",
    "    exit(1)\n",
    "\n",
    "#############################################\n",
    "#                 CONFIG\n",
    "#############################################\n",
    "\n",
    "class CFG:\n",
    "    # Paths - KEEP YOUR PATHS\n",
    "    csv_path = \"C:/zahra/EchoMind/data/5k_datapoints_1_prompt.csv\"\n",
    "    base_path = \"C:/zahra/EchoMind/data\"\n",
    "    checkpoint_path = f\"{base_path}/result/model.pt\"\n",
    "    best_model_path = f\"{base_path}/result/model_best.pt\"\n",
    "    plot_path = f\"{base_path}/result/training_curves.png\"\n",
    "    \n",
    "    # Create result directory if needed\n",
    "    os.makedirs(f\"{base_path}/result\", exist_ok=True)\n",
    "    \n",
    "    # Columns - SAME AS YOURS\n",
    "    audio_col_in = \"input_audio_path\"\n",
    "    audio_col_out = \"output_audio_path\"\n",
    "    text_col = \"prompt\"\n",
    "    \n",
    "    # Audio settings\n",
    "    sample_rate = 44100  # DAC uses 44.1kHz (better quality than 24kHz)\n",
    "    max_audio_length = 5 * 44100  # 5 seconds at 44.1kHz\n",
    "    \n",
    "    # DAC Model settings\n",
    "    dac_model_path = \"44khz\"  # Options: \"16khz\", \"24khz\", \"44khz\"\n",
    "    \n",
    "    # Training - OPTIMIZED FOR DAC\n",
    "    batch_size = 4  # Start small due to 44kHz\n",
    "    accumulation_steps = 4  # Effective batch = 16\n",
    "    epochs = 100  # More epochs for production quality\n",
    "    \n",
    "    # Learning rates - TUNED FOR DAC\n",
    "    lr_unet = 2e-5 #1e-5  # UNet learning rate\n",
    "    lr_text = 5e-7  # Text encoder learning rate (frozen mostly)\n",
    "    weight_decay = 0.01\n",
    "    grad_clip = 1.0\n",
    "    \n",
    "    # Loss weights\n",
    "    audio_loss_weight = 1.5 #1.0  # Waveform reconstruction\n",
    "    latent_loss_weight = 0.12 #0.1  # Latent space matching\n",
    "    \n",
    "    # Mixed precision\n",
    "    use_amp = True\n",
    "    \n",
    "    # Logging\n",
    "    log_interval = 100  # Print every 100 steps\n",
    "    \n",
    "    # UNet architecture - OPTIMIZED FOR DAC LATENTS\n",
    "    unet_channels = [64, 128, 256, 512]  # Deeper for better quality\n",
    "    text_dim = 768  # BERT hidden size\n",
    "    \n",
    "    # Data splits\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    test_ratio = 0.15\n",
    "    \n",
    "    # Freezing options\n",
    "    freeze_text_encoder = True  # Set False to fine-tune BERT\n",
    "    freeze_dac = True  # ALWAYS keep True (don't touch DAC)\n",
    "    \n",
    "    # Device\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Num workers\n",
    "    num_workers = 0  # Windows compatibility\n",
    "\n",
    "cfg = CFG()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DAC-VAE AUDIO EFFECT GENERATOR (No AudioTools)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Device: {cfg.device}\")\n",
    "print(f\"Sample Rate: {cfg.sample_rate} Hz\")\n",
    "print(f\"Max Length: {cfg.max_audio_length / cfg.sample_rate:.1f} seconds\")\n",
    "print(f\"Batch Size: {cfg.batch_size} x {cfg.accumulation_steps} = {cfg.batch_size * cfg.accumulation_steps}\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "#############################################\n",
    "#          LOAD DAC MODEL\n",
    "#############################################\n",
    "\n",
    "print(\"Loading DAC model...\")\n",
    "\n",
    "# Load from manually downloaded file (for offline use)\n",
    "dac_model_path = \"C:/Users/user/Downloads/weights_44khz_16kbps.pth\"\n",
    "\n",
    "if not os.path.exists(dac_model_path):\n",
    "    print(f\"\\n❌ DAC model not found at: {dac_model_path}\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MANUAL DOWNLOAD REQUIRED\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\n📥 Download Instructions:\")\n",
    "    print(\"\\n1. Go to: https://github.com/descriptinc/descript-audio-codec/releases/tag/1.0.0\")\n",
    "    print(\"2. Download: weights_44khz_16kbps.pth (245 MB)\")\n",
    "    print(f\"3. Save to: {dac_model_path}\")\n",
    "    print(\"\\n💡 TIP: Use mobile hotspot if you have network/DNS issues!\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    exit(1)\n",
    "\n",
    "print(f\"✓ Loading from: {dac_model_path}\")\n",
    "dac_model = dac.DAC.load(dac_model_path)\n",
    "dac_model = dac_model.to(cfg.device)\n",
    "dac_model.eval()\n",
    "\n",
    "# Freeze DAC encoder and decoder (we only train UNet)\n",
    "for param in dac_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(\"✓ DAC model loaded and frozen\")\n",
    "\n",
    "# Get DAC latent dimensions\n",
    "with torch.no_grad():\n",
    "    dummy_audio = torch.randn(1, 1, cfg.sample_rate).to(cfg.device)\n",
    "    # Use encoder directly (no audiotools needed!)\n",
    "    z = dac_model.encoder(dummy_audio)\n",
    "    latent_channels = z.shape[1]\n",
    "    latent_time_reduction = dummy_audio.shape[-1] // z.shape[-1]\n",
    "    \n",
    "print(f\"✓ DAC Latent Channels: {latent_channels}\")\n",
    "print(f\"✓ Time Reduction Factor: {latent_time_reduction}x\")\n",
    "print()\n",
    "\n",
    "#############################################\n",
    "#      DATASET LOADING & PREPARATION\n",
    "#############################################\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LOADING DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df = pd.read_csv(cfg.csv_path)\n",
    "print(f\"Original dataset: {len(df)} samples\")\n",
    "\n",
    "# Fix paths - SAME AS YOUR CODE\n",
    "for col in [cfg.audio_col_in, cfg.audio_col_out]:\n",
    "    df[col] = df[col].apply(lambda p: os.path.join(cfg.base_path, str(p).replace('\\\\', '/')))\n",
    "\n",
    "# Validate files exist\n",
    "print(\"\\nValidating files...\")\n",
    "valid_indices = []\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Validating\"):\n",
    "    if os.path.exists(row[cfg.audio_col_in]) and os.path.exists(row[cfg.audio_col_out]):\n",
    "        valid_indices.append(idx)\n",
    "\n",
    "df = df.iloc[valid_indices].reset_index(drop=True)\n",
    "print(f\"✓ Valid samples: {len(df)}\")\n",
    "\n",
    "# Split dataset - SAME AS YOURS\n",
    "train_df, temp_df = train_test_split(df, test_size=(cfg.val_ratio + cfg.test_ratio), random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=cfg.test_ratio/(cfg.val_ratio + cfg.test_ratio), random_state=42)\n",
    "\n",
    "print(f\"\\nDataset splits:\")\n",
    "print(f\"  Train:      {len(train_df)} samples ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Validation: {len(val_df)} samples ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Test:       {len(test_df)} samples ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "print()\n",
    "\n",
    "#############################################\n",
    "#      TOKENIZER\n",
    "#############################################\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "print(\"✓ Tokenizer loaded\\n\")\n",
    "\n",
    "#############################################\n",
    "#      DATASET CLASS\n",
    "#############################################\n",
    "\n",
    "class AudioEffectDataset(Dataset):\n",
    "    \"\"\"Dataset with soundfile (no torchcodec issues!)\"\"\"\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def _load_and_process(self, path):\n",
    "        \"\"\"Load audio using soundfile\"\"\"\n",
    "        import soundfile as sf\n",
    "        \n",
    "        # Load with soundfile (NOT torchaudio!)\n",
    "        wav, sr = sf.read(path)\n",
    "        wav = torch.from_numpy(wav).float()\n",
    "        \n",
    "        # Ensure correct shape: (channels, samples)\n",
    "        if wav.dim() == 1:\n",
    "            wav = wav.unsqueeze(0)\n",
    "        elif wav.dim() == 2 and wav.size(0) > wav.size(1):\n",
    "            wav = wav.t()\n",
    "        \n",
    "        # Resample if needed\n",
    "        if sr != cfg.sample_rate:\n",
    "            wav = torchaudio.functional.resample(wav, sr, cfg.sample_rate)\n",
    "        \n",
    "        # Convert to mono\n",
    "        if wav.size(0) > 1:\n",
    "            wav = wav.mean(dim=0, keepdim=True)\n",
    "        \n",
    "        # Pad/trim\n",
    "        if wav.size(1) > cfg.max_audio_length:\n",
    "            wav = wav[:, :cfg.max_audio_length]\n",
    "        elif wav.size(1) < cfg.max_audio_length:\n",
    "            wav = F.pad(wav, (0, cfg.max_audio_length - wav.size(1)))\n",
    "        \n",
    "        return wav\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            row = self.df.iloc[idx]\n",
    "            wav_in = self._load_and_process(row[cfg.audio_col_in])\n",
    "            wav_out = self._load_and_process(row[cfg.audio_col_out])\n",
    "            text = row[cfg.text_col]\n",
    "            \n",
    "            return wav_in, wav_out, text\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading sample {idx}: {e}\")\n",
    "            return (\n",
    "                torch.zeros(1, cfg.max_audio_length),\n",
    "                torch.zeros(1, cfg.max_audio_length),\n",
    "                \"error loading audio\"\n",
    "            )\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Collate function for batching\"\"\"\n",
    "    wav_in, wav_out, texts = zip(*batch)\n",
    "    \n",
    "    # Stack waveforms (already same length from dataset)\n",
    "    wav_in = torch.stack(wav_in)\n",
    "    wav_out = torch.stack(wav_out)\n",
    "    \n",
    "    # Tokenize texts\n",
    "    tokens = tokenizer(\n",
    "        list(texts),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    return wav_in, wav_out, tokens.input_ids, tokens.attention_mask\n",
    "\n",
    "#############################################\n",
    "#      CREATE DATALOADERS\n",
    "#############################################\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CREATING DATALOADERS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_ds = AudioEffectDataset(train_df)\n",
    "val_ds = AudioEffectDataset(val_df)\n",
    "test_ds = AudioEffectDataset(test_df)\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=cfg.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_dl = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=cfg.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=cfg.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Batches per epoch:\")\n",
    "print(f\"  Train: {len(train_dl)} batches\")\n",
    "print(f\"  Val:   {len(val_dl)} batches\")\n",
    "print(f\"  Test:  {len(test_dl)} batches\")\n",
    "print()\n",
    "\n",
    "#############################################\n",
    "#      MODEL ARCHITECTURE\n",
    "#############################################\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    \"\"\"Cross-attention between audio latents and text embeddings\"\"\"\n",
    "    \n",
    "    def __init__(self, audio_dim, text_dim, n_heads=8):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.scale = (audio_dim // n_heads) ** -0.5\n",
    "        \n",
    "        self.to_q = nn.Linear(audio_dim, audio_dim)\n",
    "        self.to_k = nn.Linear(text_dim, audio_dim)\n",
    "        self.to_v = nn.Linear(text_dim, audio_dim)\n",
    "        self.to_out = nn.Linear(audio_dim, audio_dim)\n",
    "        \n",
    "    def forward(self, x, context):\n",
    "        \"\"\"\n",
    "        x: (B, C, T) - audio features\n",
    "        context: (B, S, D) - text embeddings\n",
    "        \"\"\"\n",
    "        B, C, T = x.shape\n",
    "        x_flat = rearrange(x, 'b c t -> b t c')\n",
    "        \n",
    "        q = self.to_q(x_flat)\n",
    "        k = self.to_k(context)\n",
    "        v = self.to_v(context)\n",
    "        \n",
    "        q = rearrange(q, 'b t (h d) -> b h t d', h=self.n_heads)\n",
    "        k = rearrange(k, 'b s (h d) -> b h s d', h=self.n_heads)\n",
    "        v = rearrange(v, 'b s (h d) -> b h s d', h=self.n_heads)\n",
    "        \n",
    "        attn = torch.einsum('bhqd,bhkd->bhqk', q, k) * self.scale\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        \n",
    "        out = torch.einsum('bhqk,bhvd->bhqd', attn, v)\n",
    "        out = rearrange(out, 'b h t d -> b t (h d)')\n",
    "        out = self.to_out(out)\n",
    "        \n",
    "        return rearrange(out, 'b t c -> b c t')\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block with group normalization\"\"\"\n",
    "    \n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(channels, channels, 3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(channels, channels, 3, padding=1)\n",
    "        self.norm1 = nn.GroupNorm(8, channels)\n",
    "        self.norm2 = nn.GroupNorm(8, channels)\n",
    "        self.act = nn.SiLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.act(self.norm1(self.conv1(x)))\n",
    "        x = self.act(self.norm2(self.conv2(x)))\n",
    "        return x + residual\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    \"\"\"Downsampling block with optional cross-attention\"\"\"\n",
    "    \n",
    "    def __init__(self, in_c, out_c, text_dim=768, use_attn=False):\n",
    "        super().__init__()\n",
    "        self.use_attn = use_attn\n",
    "        \n",
    "        self.conv = nn.Conv1d(in_c, out_c, 3, padding=1)\n",
    "        self.res1 = ResidualBlock(out_c)\n",
    "        self.res2 = ResidualBlock(out_c)\n",
    "        \n",
    "        if use_attn:\n",
    "            self.attn = CrossAttention(out_c, text_dim)\n",
    "        \n",
    "        self.downsample = nn.Conv1d(out_c, out_c, 4, stride=2, padding=1)\n",
    "        \n",
    "    def forward(self, x, text_emb=None):\n",
    "        x = self.conv(x)\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        \n",
    "        if self.use_attn and text_emb is not None:\n",
    "            x = x + self.attn(x, text_emb)\n",
    "        \n",
    "        skip = x\n",
    "        x = self.downsample(x)\n",
    "        return x, skip\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    \"\"\"Upsampling block with skip connections and optional cross-attention\"\"\"\n",
    "    \n",
    "    def __init__(self, in_c, out_c, skip_c, text_dim=768, use_attn=False):\n",
    "        super().__init__()\n",
    "        self.use_attn = use_attn\n",
    "        \n",
    "        self.upsample = nn.ConvTranspose1d(in_c, out_c, 4, stride=2, padding=1)\n",
    "        self.conv = nn.Conv1d(out_c + skip_c, out_c, 3, padding=1)\n",
    "        self.res1 = ResidualBlock(out_c)\n",
    "        self.res2 = ResidualBlock(out_c)\n",
    "        \n",
    "        if use_attn:\n",
    "            self.attn = CrossAttention(out_c, text_dim)\n",
    "        \n",
    "    def forward(self, x, skip, text_emb=None):\n",
    "        x = self.upsample(x)\n",
    "        \n",
    "        # Match temporal dimensions\n",
    "        if x.size(-1) != skip.size(-1):\n",
    "            x = F.interpolate(x, size=skip.size(-1), mode='linear', align_corners=False)\n",
    "        \n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.conv(x)\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        \n",
    "        if self.use_attn and text_emb is not None:\n",
    "            x = x + self.attn(x, text_emb)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class LatentUNet(nn.Module):\n",
    "    \"\"\"UNet for manipulating DAC latent space\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_channels, channels, text_dim=768):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_conv = nn.Conv1d(latent_channels, channels[0], 7, padding=3)\n",
    "        \n",
    "        # Encoder\n",
    "        self.down_blocks = nn.ModuleList()\n",
    "        for i in range(len(channels) - 1):\n",
    "            use_attn = i >= 2  # Add attention in deeper layers\n",
    "            self.down_blocks.append(\n",
    "                DownBlock(channels[i], channels[i+1], text_dim, use_attn)\n",
    "            )\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.mid_block1 = ResidualBlock(channels[-1])\n",
    "        self.mid_attn = CrossAttention(channels[-1], text_dim)\n",
    "        self.mid_block2 = ResidualBlock(channels[-1])\n",
    "        \n",
    "        # Decoder\n",
    "        self.up_blocks = nn.ModuleList()\n",
    "        for i in range(len(channels) - 1, 0, -1):\n",
    "            use_attn = i >= 2\n",
    "            self.up_blocks.append(\n",
    "                UpBlock(\n",
    "                    in_c=channels[i],\n",
    "                    out_c=channels[i-1],\n",
    "                    skip_c=channels[i],\n",
    "                    text_dim=text_dim,\n",
    "                    use_attn=use_attn\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Output projection\n",
    "        self.output_conv = nn.Conv1d(channels[0], latent_channels, 7, padding=3)\n",
    "        \n",
    "    def forward(self, z, text_emb):\n",
    "        \"\"\"\n",
    "        z: (B, latent_channels, T) - DAC latents\n",
    "        text_emb: (B, S, text_dim) - text embeddings\n",
    "        \"\"\"\n",
    "        original_length = z.size(-1)\n",
    "        \n",
    "        x = self.input_conv(z)\n",
    "        \n",
    "        # Encoder path\n",
    "        skips = []\n",
    "        for down in self.down_blocks:\n",
    "            x, skip = down(x, text_emb)\n",
    "            skips.append(skip)\n",
    "        \n",
    "        # Bottleneck\n",
    "        x = self.mid_block1(x)\n",
    "        x = x + self.mid_attn(x, text_emb)\n",
    "        x = self.mid_block2(x)\n",
    "        \n",
    "        # Decoder path\n",
    "        for up in self.up_blocks:\n",
    "            skip = skips.pop()\n",
    "            x = up(x, skip, text_emb)\n",
    "        \n",
    "        # Output\n",
    "        x = self.output_conv(x)\n",
    "        \n",
    "        # Ensure output matches input length\n",
    "        if x.size(-1) != original_length:\n",
    "            x = F.interpolate(x, size=original_length, mode='linear', align_corners=False)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class AudioEffectModel(nn.Module):\n",
    "    \"\"\"Complete model: Text Encoder + UNet + DAC (no audiotools!)\"\"\"\n",
    "    \n",
    "    def __init__(self, dac_model, latent_channels, unet_channels, text_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Text encoder (BERT)\n",
    "        self.text_encoder = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "        \n",
    "        # Freeze/unfreeze text encoder based on config\n",
    "        if cfg.freeze_text_encoder:\n",
    "            for param in self.text_encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "            print(\"Text encoder: FROZEN ❄️\")\n",
    "        else:\n",
    "            for param in self.text_encoder.parameters():\n",
    "                param.requires_grad = True\n",
    "            print(\"Text encoder: TRAINABLE 🔥 (fine-tuning enabled)\")\n",
    "        \n",
    "        # DAC model (frozen)\n",
    "        self.dac = dac_model\n",
    "        \n",
    "        # UNet (trainable)\n",
    "        self.unet = LatentUNet(latent_channels, unet_channels, text_dim)\n",
    "        \n",
    "    def forward(self, wav_in, wav_out, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Forward pass with input validation (NO AUDIOTOOLS!)\n",
    "        \n",
    "        Returns:\n",
    "            wav_pred: Predicted output waveform\n",
    "            z_pred: Predicted latent\n",
    "            z_target: Target latent\n",
    "        \"\"\"\n",
    "        # Check for NaN in inputs\n",
    "        if torch.isnan(wav_in).any() or torch.isnan(wav_out).any():\n",
    "            return None, None, None\n",
    "        \n",
    "        # Encode text\n",
    "        text_output = self.text_encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        text_emb = text_output.last_hidden_state  # (B, S, 768)\n",
    "        \n",
    "        # Encode audio to latents using DAC (NO AUDIOTOOLS - direct encoder call!)\n",
    "        with torch.no_grad():\n",
    "            z_in = self.dac.encoder(wav_in)\n",
    "            z_target = self.dac.encoder(wav_out)\n",
    "        \n",
    "        # Check for NaN in latents\n",
    "        if torch.isnan(z_in).any() or torch.isnan(z_target).any():\n",
    "            print(\"⚠️ NaN detected in DAC encoding\")\n",
    "            return None, None, None\n",
    "        \n",
    "        # Process with UNet\n",
    "        z_pred = self.unet(z_in, text_emb)\n",
    "        \n",
    "        # Check for NaN in prediction\n",
    "        if torch.isnan(z_pred).any():\n",
    "            print(\"⚠️ NaN detected in UNet output\")\n",
    "            return None, None, None\n",
    "        \n",
    "        # Decode latents to waveform (NO AUDIOTOOLS - direct decoder call!)\n",
    "        with torch.no_grad():\n",
    "            # Decode directly - decoder only needs the latents!\n",
    "            wav_pred = self.dac.decoder(z_pred)\n",
    "        \n",
    "        # Check for NaN in decoded audio\n",
    "        if torch.isnan(wav_pred).any():\n",
    "            print(\"⚠️ NaN detected in DAC decoding\")\n",
    "            return None, None, None\n",
    "        \n",
    "        return wav_pred, z_pred, z_target\n",
    "\n",
    "def init_weights(m):\n",
    "    \"\"\"Initialize weights with small values for stability\"\"\"\n",
    "    if isinstance(m, (nn.Conv1d, nn.ConvTranspose1d)):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        m.weight.data *= 0.1  # Scale down for stability\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight, gain=0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.GroupNorm):\n",
    "        nn.init.ones_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "#############################################\n",
    "#     MODEL INITIALIZATION\n",
    "#############################################\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"INITIALIZING MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model = AudioEffectModel(\n",
    "    dac_model=dac_model,\n",
    "    latent_channels=latent_channels,\n",
    "    unet_channels=cfg.unet_channels,\n",
    "    text_dim=cfg.text_dim\n",
    ").to(cfg.device)\n",
    "\n",
    "# Initialize UNet weights\n",
    "model.unet.apply(init_weights)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Frozen parameters: {total_params - trainable_params:,}\")\n",
    "print(f\"UNet channels: {cfg.unet_channels}\")\n",
    "print(f\"Latent channels: {latent_channels}\")\n",
    "print()\n",
    "\n",
    "#############################################\n",
    "#     OPTIMIZER & LOSS\n",
    "#############################################\n",
    "\n",
    "# Optimizer based on freeze_text_encoder setting\n",
    "if cfg.freeze_text_encoder:\n",
    "    # Only optimize UNet\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.unet.parameters(),\n",
    "        lr=cfg.lr_unet,\n",
    "        weight_decay=cfg.weight_decay\n",
    "    )\n",
    "else:\n",
    "    # Optimize UNet + Text Encoder\n",
    "    optimizer = torch.optim.AdamW([\n",
    "        {\"params\": model.unet.parameters(), \"lr\": cfg.lr_unet},\n",
    "        {\"params\": model.text_encoder.parameters(), \"lr\": cfg.lr_text},\n",
    "    ], weight_decay=cfg.weight_decay)\n",
    "\n",
    "# Cosine annealing scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=cfg.epochs * len(train_dl),\n",
    "    eta_min=cfg.lr_unet * 0.1\n",
    ")\n",
    "\n",
    "# Loss functions\n",
    "criterion_audio = nn.L1Loss()\n",
    "criterion_latent = nn.MSELoss()\n",
    "\n",
    "# Mixed precision scaler\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=cfg.use_amp)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING SETUP\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Optimizer: AdamW\")\n",
    "print(f\"Learning rate: {cfg.lr_unet}\")\n",
    "print(f\"Scheduler: CosineAnnealingLR\")\n",
    "print(f\"Loss: L1 (audio) + MSE (latent)\")\n",
    "print(f\"Mixed precision: {cfg.use_amp}\")\n",
    "print()\n",
    "\n",
    "#############################################\n",
    "#     TRAINING & VALIDATION FUNCTIONS\n",
    "#############################################\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, scaler, epoch):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_audio_loss = 0\n",
    "    total_latent_loss = 0\n",
    "    nan_count = 0\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{cfg.epochs}\")\n",
    "    \n",
    "    for step, (wav_in, wav_out, ids, mask) in enumerate(pbar):\n",
    "        wav_in = wav_in.to(cfg.device)\n",
    "        wav_out = wav_out.to(cfg.device)\n",
    "        ids = ids.to(cfg.device)\n",
    "        mask = mask.to(cfg.device)\n",
    "        \n",
    "        # Check input\n",
    "        if torch.isnan(wav_in).any() or torch.isnan(wav_out).any():\n",
    "            print(f\"⚠️ NaN in input at step {step}, skipping...\")\n",
    "            nan_count += 1\n",
    "            continue\n",
    "        \n",
    "        with torch.amp.autocast('cuda', enabled=cfg.use_amp):\n",
    "            # Forward pass\n",
    "            wav_pred, z_pred, z_target = model(wav_in, wav_out, ids, mask)\n",
    "            \n",
    "            # Check for None (indicates NaN in forward pass)\n",
    "            if wav_pred is None:\n",
    "                nan_count += 1\n",
    "                continue\n",
    "            \n",
    "            # Match lengths\n",
    "            if wav_pred.size(-1) != wav_out.size(-1):\n",
    "                min_len = min(wav_pred.size(-1), wav_out.size(-1))\n",
    "                wav_pred = wav_pred[..., :min_len]\n",
    "                wav_out = wav_out[..., :min_len]\n",
    "            \n",
    "            if z_pred.size(-1) != z_target.size(-1):\n",
    "                min_len = min(z_pred.size(-1), z_target.size(-1))\n",
    "                z_pred = z_pred[..., :min_len]\n",
    "                z_target = z_target[..., :min_len]\n",
    "            \n",
    "            # Compute losses\n",
    "            audio_loss = criterion_audio(wav_pred, wav_out)\n",
    "            latent_loss = criterion_latent(z_pred, z_target)\n",
    "            \n",
    "            loss = (cfg.audio_loss_weight * audio_loss + \n",
    "                   cfg.latent_loss_weight * latent_loss)\n",
    "            \n",
    "            # Scale for gradient accumulation\n",
    "            loss = loss / cfg.accumulation_steps\n",
    "        \n",
    "        # Check loss\n",
    "        if torch.isnan(loss) or torch.isinf(loss):\n",
    "            print(f\"⚠️ NaN/Inf loss at step {step}, skipping...\")\n",
    "            nan_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # Optimizer step (with gradient accumulation)\n",
    "        if (step + 1) % cfg.accumulation_steps == 0:\n",
    "            # Unscale gradients\n",
    "            scaler.unscale_(optimizer)\n",
    "            \n",
    "            # Clip gradients\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "                model.parameters(),\n",
    "                cfg.grad_clip\n",
    "            )\n",
    "            \n",
    "            # Check gradient norm\n",
    "            if torch.isnan(grad_norm) or torch.isinf(grad_norm) or grad_norm > 100:\n",
    "                print(f\"⚠️ Bad gradient (norm={grad_norm:.2f}) at step {step}, skipping...\")\n",
    "                optimizer.zero_grad()\n",
    "                scaler.update()\n",
    "                nan_count += 1\n",
    "                continue\n",
    "            \n",
    "            # Update weights\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # Accumulate losses\n",
    "        total_loss += loss.item() * cfg.accumulation_steps\n",
    "        total_audio_loss += audio_loss.item()\n",
    "        total_latent_loss += latent_loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item() * cfg.accumulation_steps:.4f}',\n",
    "            'audio': f'{audio_loss.item():.4f}',\n",
    "            'latent': f'{latent_loss.item():.4f}',\n",
    "            'nans': nan_count\n",
    "        })\n",
    "        \n",
    "        # Log every N steps\n",
    "        if (step + 1) % cfg.log_interval == 0:\n",
    "            avg_loss = total_loss / (step + 1)\n",
    "            print(f\"\\n  Step {step+1}/{len(dataloader)} | \"\n",
    "                  f\"Loss: {avg_loss:.6f} | \"\n",
    "                  f\"Audio: {total_audio_loss/(step+1):.6f} | \"\n",
    "                  f\"Latent: {total_latent_loss/(step+1):.6f} | \"\n",
    "                  f\"NaNs: {nan_count}\")\n",
    "    \n",
    "    if nan_count > 0:\n",
    "        print(f\"\\n⚠️ Epoch had {nan_count} NaN occurrences\")\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_audio_loss = total_audio_loss / len(dataloader)\n",
    "    avg_latent_loss = total_latent_loss / len(dataloader)\n",
    "    \n",
    "    return avg_loss, avg_audio_loss, avg_latent_loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_epoch(model, dataloader, epoch):\n",
    "    \"\"\"Validate for one epoch\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_audio_loss = 0\n",
    "    total_latent_loss = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f\"Validation {epoch+1}/{cfg.epochs}\")\n",
    "    \n",
    "    for wav_in, wav_out, ids, mask in pbar:\n",
    "        wav_in = wav_in.to(cfg.device)\n",
    "        wav_out = wav_out.to(cfg.device)\n",
    "        ids = ids.to(cfg.device)\n",
    "        mask = mask.to(cfg.device)\n",
    "        \n",
    "        with torch.amp.autocast('cuda', enabled=cfg.use_amp):\n",
    "            wav_pred, z_pred, z_target = model(wav_in, wav_out, ids, mask)\n",
    "            \n",
    "            if wav_pred is None:\n",
    "                continue\n",
    "            \n",
    "            # Match lengths\n",
    "            if wav_pred.size(-1) != wav_out.size(-1):\n",
    "                min_len = min(wav_pred.size(-1), wav_out.size(-1))\n",
    "                wav_pred = wav_pred[..., :min_len]\n",
    "                wav_out = wav_out[..., :min_len]\n",
    "            \n",
    "            if z_pred.size(-1) != z_target.size(-1):\n",
    "                min_len = min(z_pred.size(-1), z_target.size(-1))\n",
    "                z_pred = z_pred[..., :min_len]\n",
    "                z_target = z_target[..., :min_len]\n",
    "            \n",
    "            audio_loss = criterion_audio(wav_pred, wav_out)\n",
    "            latent_loss = criterion_latent(z_pred, z_target)\n",
    "            \n",
    "            loss = (cfg.audio_loss_weight * audio_loss + \n",
    "                   cfg.latent_loss_weight * latent_loss)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_audio_loss += audio_loss.item()\n",
    "        total_latent_loss += latent_loss.item()\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'audio': f'{audio_loss.item():.4f}',\n",
    "            'latent': f'{latent_loss.item():.4f}'\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_audio_loss = total_audio_loss / len(dataloader)\n",
    "    avg_latent_loss = total_latent_loss / len(dataloader)\n",
    "    \n",
    "    return avg_loss, avg_audio_loss, avg_latent_loss\n",
    "\n",
    "#############################################\n",
    "#     TRAINING LOOP\n",
    "#############################################\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total epochs: {cfg.epochs}\")\n",
    "print(f\"Steps per epoch: {len(train_dl)}\")\n",
    "print(f\"Validation every epoch\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Training history\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_audio_losses = []\n",
    "train_latent_losses = []\n",
    "val_audio_losses = []\n",
    "val_latent_losses = []\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "start_epoch = 0\n",
    "\n",
    "# Resume from checkpoint if exists\n",
    "if os.path.exists(cfg.checkpoint_path):\n",
    "    print(\"Loading checkpoint...\")\n",
    "    ckpt = torch.load(cfg.checkpoint_path, map_location=cfg.device)\n",
    "    model.load_state_dict(ckpt['model'])\n",
    "    optimizer.load_state_dict(ckpt['optimizer'])\n",
    "    scheduler.load_state_dict(ckpt['scheduler'])\n",
    "    scaler.load_state_dict(ckpt['scaler'])\n",
    "    start_epoch = ckpt['epoch'] + 1\n",
    "    train_losses = ckpt.get('train_losses', [])\n",
    "    val_losses = ckpt.get('val_losses', [])\n",
    "    train_audio_losses = ckpt.get('train_audio_losses', [])\n",
    "    train_latent_losses = ckpt.get('train_latent_losses', [])\n",
    "    val_audio_losses = ckpt.get('val_audio_losses', [])\n",
    "    val_latent_losses = ckpt.get('val_latent_losses', [])\n",
    "    best_val_loss = ckpt.get('best_val_loss', float('inf'))\n",
    "    print(f\"✓ Resumed from epoch {start_epoch}\")\n",
    "    print()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(start_epoch, cfg.epochs):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EPOCH {epoch+1}/{cfg.epochs}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_audio, train_latent = train_epoch(\n",
    "        model, train_dl, optimizer, scheduler, scaler, epoch\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_audio, val_latent = validate_epoch(\n",
    "        model, val_dl, epoch\n",
    "    )\n",
    "    \n",
    "    # Store losses\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_audio_losses.append(train_audio)\n",
    "    train_latent_losses.append(train_latent)\n",
    "    val_audio_losses.append(val_audio)\n",
    "    val_latent_losses.append(val_latent)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EPOCH {epoch+1}/{cfg.epochs} SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Train Loss:  {train_loss:.6f} (Audio: {train_audio:.6f}, Latent: {train_latent:.6f})\")\n",
    "    print(f\"Val Loss:    {val_loss:.6f} (Audio: {val_audio:.6f}, Latent: {val_latent:.6f})\")\n",
    "    print(f\"Learning Rate: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Save checkpoint\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'scheduler': scheduler.state_dict(),\n",
    "        'scaler': scaler.state_dict(),\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_audio_losses': train_audio_losses,\n",
    "        'train_latent_losses': train_latent_losses,\n",
    "        'val_audio_losses': val_audio_losses,\n",
    "        'val_latent_losses': val_latent_losses,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'config': {\n",
    "            'latent_channels': latent_channels,\n",
    "            'unet_channels': cfg.unet_channels,\n",
    "            'text_dim': cfg.text_dim,\n",
    "            'sample_rate': cfg.sample_rate\n",
    "        }\n",
    "    }\n",
    "    torch.save(checkpoint, cfg.checkpoint_path)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'val_loss': best_val_loss,\n",
    "            'config': checkpoint['config']\n",
    "        }, cfg.best_model_path)\n",
    "        print(f\"✅ NEW BEST MODEL! Val Loss: {best_val_loss:.6f}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "#############################################\n",
    "#     TEST SET EVALUATION\n",
    "#############################################\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TESTING BEST MODEL\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Load best model\n",
    "best_ckpt = torch.load(cfg.best_model_path, map_location=cfg.device)\n",
    "model.load_state_dict(best_ckpt['model'])\n",
    "print(f\"Loaded best model from epoch {best_ckpt['epoch']}\")\n",
    "\n",
    "# Test\n",
    "test_loss, test_audio, test_latent = validate_epoch(model, test_dl, cfg.epochs)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"FINAL TEST RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Test Loss:  {test_loss:.6f}\")\n",
    "print(f\"  Audio Loss:  {test_audio:.6f}\")\n",
    "print(f\"  Latent Loss: {test_latent:.6f}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "#############################################\n",
    "#     PLOT TRAINING CURVES\n",
    "#############################################\n",
    "\n",
    "print(\"Generating training curves...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Total loss\n",
    "ax = axes[0, 0]\n",
    "epochs_range = range(len(train_losses))\n",
    "ax.plot(epochs_range, train_losses, 'b-', label='Train', linewidth=2, marker='o', markersize=4)\n",
    "ax.plot(epochs_range, val_losses, 'r-', label='Val', linewidth=2, marker='s', markersize=4)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Total Loss', fontsize=12)\n",
    "ax.set_title('Total Loss (Audio + Latent)', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Audio loss\n",
    "ax = axes[0, 1]\n",
    "ax.plot(epochs_range, train_audio_losses, 'b-', label='Train', linewidth=2, marker='o', markersize=4)\n",
    "ax.plot(epochs_range, val_audio_losses, 'r-', label='Val', linewidth=2, marker='s', markersize=4)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Audio Loss (L1)', fontsize=12)\n",
    "ax.set_title('Audio Reconstruction Loss', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Latent loss\n",
    "ax = axes[1, 0]\n",
    "ax.plot(epochs_range, train_latent_losses, 'b-', label='Train', linewidth=2, marker='o', markersize=4)\n",
    "ax.plot(epochs_range, val_latent_losses, 'r-', label='Val', linewidth=2, marker='s', markersize=4)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Latent Loss (MSE)', fontsize=12)\n",
    "ax.set_title('Latent Space Loss', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Generalization gap\n",
    "ax = axes[1, 1]\n",
    "gap = [v - t for t, v in zip(train_losses, val_losses)]\n",
    "ax.plot(epochs_range, gap, 'g-', label='Val - Train', linewidth=2, marker='d', markersize=4)\n",
    "ax.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Loss Gap', fontsize=12)\n",
    "ax.set_title('Generalization Gap (Val - Train)', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(cfg.plot_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"✓ Plot saved to: {cfg.plot_path}\")\n",
    "plt.close()\n",
    "\n",
    "#############################################\n",
    "#     SAVE SUMMARY\n",
    "#############################################\n",
    "\n",
    "summary = {\n",
    "    'dataset': {\n",
    "        'total_samples': len(df),\n",
    "        'train_samples': len(train_df),\n",
    "        'val_samples': len(val_df),\n",
    "        'test_samples': len(test_df)\n",
    "    },\n",
    "    'training': {\n",
    "        'epochs': cfg.epochs,\n",
    "        'batch_size': cfg.batch_size,\n",
    "        'accumulation_steps': cfg.accumulation_steps,\n",
    "        'effective_batch_size': cfg.batch_size * cfg.accumulation_steps\n",
    "    },\n",
    "    'model': {\n",
    "        'total_parameters': total_params,\n",
    "        'trainable_parameters': trainable_params,\n",
    "        'latent_channels': latent_channels,\n",
    "        'unet_channels': cfg.unet_channels\n",
    "    },\n",
    "    'results': {\n",
    "        'best_train_loss': float(min(train_losses)),\n",
    "        'best_val_loss': float(best_val_loss),\n",
    "        'test_loss': float(test_loss),\n",
    "        'test_audio_loss': float(test_audio),\n",
    "        'test_latent_loss': float(test_latent)\n",
    "    },\n",
    "    'config': {\n",
    "        'sample_rate': cfg.sample_rate,\n",
    "        'max_audio_length': cfg.max_audio_length,\n",
    "        'lr_unet': cfg.lr_unet,\n",
    "        'audio_loss_weight': cfg.audio_loss_weight,\n",
    "        'latent_loss_weight': cfg.latent_loss_weight\n",
    "    }\n",
    "}\n",
    "\n",
    "summary_path = f\"{cfg.base_path}/result_DAC/training_summary.json\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"✓ Summary saved to: {summary_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL FILES SAVED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"✓ Best model: {cfg.best_model_path}\")\n",
    "print(f\"✓ Checkpoint: {cfg.checkpoint_path}\")\n",
    "print(f\"✓ Training curves: {cfg.plot_path}\")\n",
    "print(f\"✓ Summary: {summary_path}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n🎉 TRAINING PIPELINE COMPLETE! 🎉\\n\")\n",
    "print(\"Next steps:\")\n",
    "print(\"1. Check training curves for convergence\")\n",
    "print(\"2. Use inference script to test on new audio\")\n",
    "print(\"3. Fine-tune hyperparameters if needed\")\n",
    "print(\"\\nGood luck with your production model! 🚀\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab2c6f5-c63a-4c81-b8b5-39d56c0d0aca",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbed36b6-630b-4b5b-93f6-d8ba15655565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ DAC library imported successfully\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Inference Script for DAC-VAE Audio Effect Generator (NO AUDIOTOOLS)\n",
    "Test your trained model on new audio files\n",
    "\n",
    "FIXED VERSION:\n",
    "- No audiotools dependency\n",
    "- Correct decoder API (simple call)\n",
    "- Offline DAC model loading\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from einops import rearrange\n",
    "import argparse\n",
    "\n",
    "# DAC import (NO audiotools!)\n",
    "try:\n",
    "    import dac\n",
    "    print(\"✓ DAC library imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"❌ DAC not installed. Run: pip install descript-audio-codec\")\n",
    "    exit(1)\n",
    "\n",
    "#############################################\n",
    "#     MODEL ARCHITECTURE (SAME AS TRAINING)\n",
    "#############################################\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    \"\"\"Cross-attention between audio latents and text embeddings\"\"\"\n",
    "    \n",
    "    def __init__(self, audio_dim, text_dim, n_heads=8):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.scale = (audio_dim // n_heads) ** -0.5\n",
    "        self.to_q = nn.Linear(audio_dim, audio_dim)\n",
    "        self.to_k = nn.Linear(text_dim, audio_dim)\n",
    "        self.to_v = nn.Linear(text_dim, audio_dim)\n",
    "        self.to_out = nn.Linear(audio_dim, audio_dim)\n",
    "        \n",
    "    def forward(self, x, context):\n",
    "        B, C, T = x.shape\n",
    "        x_flat = rearrange(x, 'b c t -> b t c')\n",
    "        q = self.to_q(x_flat)\n",
    "        k = self.to_k(context)\n",
    "        v = self.to_v(context)\n",
    "        q = rearrange(q, 'b t (h d) -> b h t d', h=self.n_heads)\n",
    "        k = rearrange(k, 'b s (h d) -> b h s d', h=self.n_heads)\n",
    "        v = rearrange(v, 'b s (h d) -> b h s d', h=self.n_heads)\n",
    "        attn = torch.einsum('bhqd,bhkd->bhqk', q, k) * self.scale\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        out = torch.einsum('bhqk,bhvd->bhqd', attn, v)\n",
    "        out = rearrange(out, 'b h t d -> b t (h d)')\n",
    "        out = self.to_out(out)\n",
    "        return rearrange(out, 'b t c -> b c t')\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block with group normalization\"\"\"\n",
    "    \n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(channels, channels, 3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(channels, channels, 3, padding=1)\n",
    "        self.norm1 = nn.GroupNorm(8, channels)\n",
    "        self.norm2 = nn.GroupNorm(8, channels)\n",
    "        self.act = nn.SiLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.act(self.norm1(self.conv1(x)))\n",
    "        x = self.act(self.norm2(self.conv2(x)))\n",
    "        return x + residual\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    \"\"\"Downsampling block with optional cross-attention\"\"\"\n",
    "    \n",
    "    def __init__(self, in_c, out_c, text_dim=768, use_attn=False):\n",
    "        super().__init__()\n",
    "        self.use_attn = use_attn\n",
    "        self.conv = nn.Conv1d(in_c, out_c, 3, padding=1)\n",
    "        self.res1 = ResidualBlock(out_c)\n",
    "        self.res2 = ResidualBlock(out_c)\n",
    "        if use_attn:\n",
    "            self.attn = CrossAttention(out_c, text_dim)\n",
    "        self.downsample = nn.Conv1d(out_c, out_c, 4, stride=2, padding=1)\n",
    "        \n",
    "    def forward(self, x, text_emb=None):\n",
    "        x = self.conv(x)\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        if self.use_attn and text_emb is not None:\n",
    "            x = x + self.attn(x, text_emb)\n",
    "        skip = x\n",
    "        x = self.downsample(x)\n",
    "        return x, skip\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    \"\"\"Upsampling block with skip connections and optional cross-attention\"\"\"\n",
    "    \n",
    "    def __init__(self, in_c, out_c, skip_c, text_dim=768, use_attn=False):\n",
    "        super().__init__()\n",
    "        self.use_attn = use_attn\n",
    "        self.upsample = nn.ConvTranspose1d(in_c, out_c, 4, stride=2, padding=1)\n",
    "        self.conv = nn.Conv1d(out_c + skip_c, out_c, 3, padding=1)\n",
    "        self.res1 = ResidualBlock(out_c)\n",
    "        self.res2 = ResidualBlock(out_c)\n",
    "        if use_attn:\n",
    "            self.attn = CrossAttention(out_c, text_dim)\n",
    "        \n",
    "    def forward(self, x, skip, text_emb=None):\n",
    "        x = self.upsample(x)\n",
    "        if x.size(-1) != skip.size(-1):\n",
    "            x = F.interpolate(x, size=skip.size(-1), mode='linear', align_corners=False)\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.conv(x)\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        if self.use_attn and text_emb is not None:\n",
    "            x = x + self.attn(x, text_emb)\n",
    "        return x\n",
    "\n",
    "class LatentUNet(nn.Module):\n",
    "    \"\"\"UNet for manipulating DAC latent space\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_channels, channels, text_dim=768):\n",
    "        super().__init__()\n",
    "        self.input_conv = nn.Conv1d(latent_channels, channels[0], 7, padding=3)\n",
    "        \n",
    "        self.down_blocks = nn.ModuleList()\n",
    "        for i in range(len(channels) - 1):\n",
    "            use_attn = i >= 2\n",
    "            self.down_blocks.append(DownBlock(channels[i], channels[i+1], text_dim, use_attn))\n",
    "        \n",
    "        self.mid_block1 = ResidualBlock(channels[-1])\n",
    "        self.mid_attn = CrossAttention(channels[-1], text_dim)\n",
    "        self.mid_block2 = ResidualBlock(channels[-1])\n",
    "        \n",
    "        self.up_blocks = nn.ModuleList()\n",
    "        for i in range(len(channels) - 1, 0, -1):\n",
    "            use_attn = i >= 2\n",
    "            self.up_blocks.append(\n",
    "                UpBlock(channels[i], channels[i-1], channels[i], text_dim, use_attn)\n",
    "            )\n",
    "        \n",
    "        self.output_conv = nn.Conv1d(channels[0], latent_channels, 7, padding=3)\n",
    "        \n",
    "    def forward(self, z, text_emb):\n",
    "        original_length = z.size(-1)\n",
    "        x = self.input_conv(z)\n",
    "        \n",
    "        skips = []\n",
    "        for down in self.down_blocks:\n",
    "            x, skip = down(x, text_emb)\n",
    "            skips.append(skip)\n",
    "        \n",
    "        x = self.mid_block1(x)\n",
    "        x = x + self.mid_attn(x, text_emb)\n",
    "        x = self.mid_block2(x)\n",
    "        \n",
    "        for up in self.up_blocks:\n",
    "            skip = skips.pop()\n",
    "            x = up(x, skip, text_emb)\n",
    "        \n",
    "        x = self.output_conv(x)\n",
    "        \n",
    "        if x.size(-1) != original_length:\n",
    "            x = F.interpolate(x, size=original_length, mode='linear', align_corners=False)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class AudioEffectModel(nn.Module):\n",
    "    \"\"\"Complete model: Text Encoder + UNet + DAC (NO AUDIOTOOLS!)\"\"\"\n",
    "    \n",
    "    def __init__(self, dac_model, latent_channels, unet_channels, text_dim):\n",
    "        super().__init__()\n",
    "        self.text_encoder = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.dac = dac_model\n",
    "        self.unet = LatentUNet(latent_channels, unet_channels, text_dim)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def generate(self, wav_in, prompt, sample_rate):\n",
    "        \"\"\"\n",
    "        Generate audio with effect applied (NO AUDIOTOOLS!)\n",
    "        \n",
    "        Args:\n",
    "            wav_in: Input waveform (1, 1, T) or (1, T)\n",
    "            prompt: Text description of effect (string)\n",
    "            sample_rate: Sample rate of input audio\n",
    "            \n",
    "        Returns:\n",
    "            wav_out: Output waveform with effect applied\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        \n",
    "        # Ensure correct shape\n",
    "        if wav_in.dim() == 2:\n",
    "            wav_in = wav_in.unsqueeze(1)\n",
    "        \n",
    "        # Tokenize prompt\n",
    "        tokens = tokenizer(\n",
    "            [prompt],\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(wav_in.device)\n",
    "        \n",
    "        # Encode text\n",
    "        text_output = self.text_encoder(\n",
    "            input_ids=tokens.input_ids,\n",
    "            attention_mask=tokens.attention_mask\n",
    "        )\n",
    "        text_emb = text_output.last_hidden_state\n",
    "        \n",
    "        # Encode audio to latents (NO AUDIOTOOLS - direct encoder!)\n",
    "        z_in = self.dac.encoder(wav_in)\n",
    "        \n",
    "        # Process with UNet\n",
    "        z_out = self.unet(z_in, text_emb)\n",
    "        \n",
    "        # Decode to waveform (FIXED - simple decoder call!)\n",
    "        wav_out = self.dac.decoder(z_out)\n",
    "        \n",
    "        return wav_out\n",
    "\n",
    "#############################################\n",
    "#     INFERENCE CLASS\n",
    "#############################################\n",
    "\n",
    "#############################################\n",
    "#     INFERENCE CLASS (FIXED FOR WINDOWS)\n",
    "#############################################\n",
    "\n",
    "class AudioEffectInference:\n",
    "    def __init__(self, model_path, dac_model_path=None, device='cuda'):\n",
    "        \"\"\"\n",
    "        Initialize inference pipeline\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to trained model checkpoint (.pt file)\n",
    "            dac_model_path: Path to DAC weights (optional, defaults to cache location)\n",
    "            device: 'cuda' or 'cpu'\n",
    "        \"\"\"\n",
    "        self.device = device if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        print(\"LOADING MODEL FOR INFERENCE (NO AUDIOTOOLS)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Load checkpoint\n",
    "        print(f\"Loading checkpoint from: {model_path}\")\n",
    "        ckpt = torch.load(model_path, map_location=self.device)\n",
    "        \n",
    "        # Get config\n",
    "        config = ckpt['config']\n",
    "        self.sample_rate = config['sample_rate']\n",
    "        latent_channels = config['latent_channels']\n",
    "        unet_channels = config['unet_channels']\n",
    "        text_dim = config['text_dim']\n",
    "        \n",
    "        print(f\"✓ Sample rate: {self.sample_rate} Hz\")\n",
    "        print(f\"✓ Latent channels: {latent_channels}\")\n",
    "        print(f\"✓ UNet channels: {unet_channels}\")\n",
    "        \n",
    "        # Load DAC model from local file\n",
    "        if dac_model_path is None:\n",
    "            dac_model_path = \"C:/Users/user/Downloads/weights_44khz_16kbps.pth\"\n",
    "        \n",
    "        print(f\"Loading DAC model from: {dac_model_path}\")\n",
    "        \n",
    "        if not os.path.exists(dac_model_path):\n",
    "            print(f\"\\n❌ DAC model not found at: {dac_model_path}\")\n",
    "            print(\"Please download it first!\")\n",
    "            exit(1)\n",
    "        \n",
    "        self.dac_model = dac.DAC.load(dac_model_path)\n",
    "        self.dac_model = self.dac_model.to(self.device)\n",
    "        self.dac_model.eval()\n",
    "        print(\"✓ DAC model loaded\")\n",
    "        \n",
    "        # Create model\n",
    "        self.model = AudioEffectModel(\n",
    "            dac_model=self.dac_model,\n",
    "            latent_channels=latent_channels,\n",
    "            unet_channels=unet_channels,\n",
    "            text_dim=text_dim\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Load weights\n",
    "        self.model.load_state_dict(ckpt['model'])\n",
    "        self.model.eval()\n",
    "        print(\"✓ Model weights loaded\")\n",
    "        \n",
    "        # Load tokenizer\n",
    "        global tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        print(\"✓ Tokenizer loaded\")\n",
    "        \n",
    "        print(f\"✓ Device: {self.device}\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    def process_audio(self, input_path, output_path, prompt):\n",
    "        \"\"\"\n",
    "        Process audio file with effect (FIXED for Windows - uses soundfile!)\n",
    "        \n",
    "        Args:\n",
    "            input_path: Path to input audio file\n",
    "            output_path: Path to save output audio\n",
    "            prompt: Text description of effect to apply\n",
    "        \"\"\"\n",
    "        import soundfile as sf\n",
    "        \n",
    "        print(f\"Processing: {input_path}\")\n",
    "        print(f\"Effect: '{prompt}'\")\n",
    "        \n",
    "        # Load audio using soundfile (NOT torchaudio!)\n",
    "        wav, sr = sf.read(input_path)\n",
    "        wav = torch.from_numpy(wav).float()\n",
    "        \n",
    "        # Ensure correct shape: (channels, samples)\n",
    "        if wav.dim() == 1:\n",
    "            wav = wav.unsqueeze(0)  # (samples,) -> (1, samples)\n",
    "        elif wav.dim() == 2 and wav.size(0) > wav.size(1):\n",
    "            wav = wav.t()  # (samples, channels) -> (channels, samples)\n",
    "        \n",
    "        original_length = wav.size(-1)\n",
    "        \n",
    "        # Resample if needed\n",
    "        if sr != self.sample_rate:\n",
    "            print(f\"Resampling from {sr} Hz to {self.sample_rate} Hz\")\n",
    "            wav = torchaudio.functional.resample(wav, sr, self.sample_rate)\n",
    "        \n",
    "        # Convert to mono\n",
    "        if wav.size(0) > 1:\n",
    "            print(\"Converting to mono\")\n",
    "            wav = wav.mean(dim=0, keepdim=True)\n",
    "        \n",
    "        # Add batch dimension and move to device\n",
    "        wav = wav.unsqueeze(0).to(self.device)  # (1, 1, samples)\n",
    "        \n",
    "        print(f\"Input shape: {wav.shape}\")\n",
    "        print(\"Generating...\")\n",
    "        \n",
    "        # Generate\n",
    "        with torch.no_grad():\n",
    "            wav_out = self.model.generate(wav, prompt, self.sample_rate)\n",
    "        \n",
    "        # Move to CPU and remove batch dimension\n",
    "        wav_out = wav_out.squeeze(0).cpu()  # (1, samples)\n",
    "        \n",
    "        # Match original length (approximately)\n",
    "        current_length = wav_out.size(-1)\n",
    "        target_length = wav.squeeze(0).size(-1)\n",
    "        \n",
    "        if current_length != target_length:\n",
    "            print(f\"Adjusting length: {current_length} -> {target_length}\")\n",
    "            if current_length > target_length:\n",
    "                wav_out = wav_out[..., :target_length]\n",
    "            else:\n",
    "                wav_out = F.pad(wav_out, (0, target_length - current_length))\n",
    "        \n",
    "        print(f\"Output shape: {wav_out.shape}\")\n",
    "        \n",
    "        # Save using soundfile (NOT torchaudio.save!)\n",
    "        wav_out_np = wav_out.squeeze(0).numpy()  # (samples,)\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        sf.write(output_path, wav_out_np, self.sample_rate)\n",
    "        \n",
    "        print(f\"✓ Saved to: {output_path}\\n\")\n",
    "    \n",
    "    def batch_process(self, input_dir, output_dir, prompt):\n",
    "        \"\"\"\n",
    "        Process all audio files in a directory\n",
    "        \n",
    "        Args:\n",
    "            input_dir: Directory containing input audio files\n",
    "            output_dir: Directory to save output audio files\n",
    "            prompt: Text description of effect to apply\n",
    "        \"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Get all audio files\n",
    "        audio_extensions = ['.wav', '.mp3', '.flac', '.ogg', '.m4a']\n",
    "        audio_files = [\n",
    "            f for f in os.listdir(input_dir)\n",
    "            if os.path.splitext(f)[1].lower() in audio_extensions\n",
    "        ]\n",
    "        \n",
    "        if not audio_files:\n",
    "            print(f\"❌ No audio files found in {input_dir}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Found {len(audio_files)} audio files\")\n",
    "        print(f\"Effect: '{prompt}'\\n\")\n",
    "        \n",
    "        for i, filename in enumerate(audio_files, 1):\n",
    "            print(f\"[{i}/{len(audio_files)}] Processing: {filename}\")\n",
    "            \n",
    "            input_path = os.path.join(input_dir, filename)\n",
    "            # Keep original extension\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            output_filename = f\"{name}_processed{ext}\"\n",
    "            output_path = os.path.join(output_dir, output_filename)\n",
    "            \n",
    "            try:\n",
    "                self.process_audio(input_path, output_path, prompt)\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error processing {filename}: {e}\\n\")\n",
    "        \n",
    "        print(f\"\\n✅ Batch processing complete!\")\n",
    "        print(f\"   Processed: {len(audio_files)} files\")\n",
    "        print(f\"   Output directory: {output_dir}\")\n",
    "       \n",
    "\n",
    "#############################################\n",
    "#     MAIN FUNCTION\n",
    "#############################################\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Audio Effect Generator Inference (DAC-VAE)',\n",
    "        formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "        epilog=\"\"\"\n",
    "Examples:\n",
    "  # Process single file\n",
    "  python dac_vae_inference_FIXED.py --model model_best.pt --input audio.wav --output result.wav --prompt \"add rain sounds\"\n",
    "  \n",
    "  # Batch process directory\n",
    "  python dac_vae_inference_FIXED.py --model model_best.pt --input input_folder/ --output output_folder/ --prompt \"add birds chirping\"\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    parser.add_argument('--model', type=str, required=True,\n",
    "                       help='Path to trained model checkpoint (.pt file)')\n",
    "    parser.add_argument('--input', type=str, required=True,\n",
    "                       help='Input audio file or directory')\n",
    "    parser.add_argument('--output', type=str, required=True,\n",
    "                       help='Output audio file or directory')\n",
    "    parser.add_argument('--prompt', type=str, required=True,\n",
    "                       help='Effect description (e.g., \"add rain sounds\")')\n",
    "    parser.add_argument('--dac-model', type=str, default=None,\n",
    "                       help='Path to DAC model weights (default: C:/Users/user/Downloads/weights_44khz_16kbps.pth)')\n",
    "    parser.add_argument('--device', type=str, default='cuda',\n",
    "                       help='Device to use (cuda or cpu)')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Initialize inference\n",
    "    try:\n",
    "        inference = AudioEffectInference(args.model, args.dac_model, args.device)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load model: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Check if input is file or directory\n",
    "    if os.path.isfile(args.input):\n",
    "        # Single file\n",
    "        inference.process_audio(args.input, args.output, args.prompt)\n",
    "    elif os.path.isdir(args.input):\n",
    "        # Batch processing\n",
    "        inference.batch_process(args.input, args.output, args.prompt)\n",
    "    else:\n",
    "        print(f\"❌ Error: {args.input} is not a valid file or directory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4b00aab-f719-43bc-ae10-520e19701aef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOADING MODEL FOR INFERENCE (NO AUDIOTOOLS)\n",
      "============================================================\n",
      "Loading checkpoint from: C:/zahra/EchoMind/data/result/model_best.pt\n",
      "✓ Sample rate: 44100 Hz\n",
      "✓ Latent channels: 128\n",
      "✓ UNet channels: [64, 128, 256, 512]\n",
      "Loading DAC model from: C:/Users/user/Downloads/weights_44khz_16kbps.pth\n",
      "✓ DAC model loaded\n",
      "✓ Model weights loaded\n",
      "✓ Tokenizer loaded\n",
      "✓ Device: cuda\n",
      "============================================================\n",
      "\n",
      "Processing: C:/zahra/EchoMind/data/audios/input_audios/22.wav\n",
      "Effect: 'add lightning sounds'\n",
      "Resampling from 22050 Hz to 44100 Hz\n",
      "Input shape: torch.Size([1, 1, 220500])\n",
      "Generating...\n",
      "Adjusting length: 220160 -> 220500\n",
      "Output shape: torch.Size([1, 220500])\n",
      "✓ Saved to: C:/zahra/EchoMind/data/result/inference100/22_lightning.wav\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --model MODEL --input\n",
      "                             INPUT --output OUTPUT --prompt\n",
      "                             PROMPT [--dac-model DAC_MODEL]\n",
      "                             [--device DEVICE]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --model, --input, --output, --prompt\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Example usage (can be run directly or via command line)\n",
    "    #C:/Users/user/Downloads/weights_44khz_16kbps.pth\n",
    "    # For direct usage in script:\n",
    "    \n",
    "    model_path = \"C:/zahra/EchoMind/data/result/model_best.pt\"\n",
    "    input_audio = \"C:/zahra/EchoMind/data/audios/input_audios/22.wav\"\n",
    "    output_audio = \"C:/zahra/EchoMind/data/result/inference100/22_lightning.wav\"\n",
    "    effect_prompt = \"add lightning sounds\"\n",
    "    \n",
    "    inference = AudioEffectInference(model_path, dac_model_path=\"C:/Users/user/Downloads/weights_44khz_16kbps.pth\", device='cuda')\n",
    "    inference.process_audio(input_audio, output_audio, effect_prompt)\n",
    "    \n",
    "    # For command line usage:\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1804030-d443-482b-8115-5fe5114d15ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOADING MODEL FOR INFERENCE (NO AUDIOTOOLS)\n",
      "============================================================\n",
      "Loading checkpoint from: C:/zahra/EchoMind/data/result/model_best.pt\n",
      "✓ Sample rate: 44100 Hz\n",
      "✓ Latent channels: 128\n",
      "✓ UNet channels: [64, 128, 256, 512]\n",
      "Loading DAC model from: C:/Users/user/Downloads/weights_44khz_16kbps.pth\n",
      "✓ DAC model loaded\n",
      "✓ Model weights loaded\n",
      "✓ Tokenizer loaded\n",
      "✓ Device: cuda\n",
      "============================================================\n",
      "\n",
      "Processing: C:/zahra/EchoMind/data/result/inference/english_OJCIvTNk.wav\n",
      "Effect: 'add lightning sounds'\n",
      "Resampling from 48000 Hz to 44100 Hz\n",
      "Converting to mono\n",
      "Input shape: torch.Size([1, 1, 213003])\n",
      "Generating...\n",
      "Adjusting length: 212992 -> 213003\n",
      "Output shape: torch.Size([1, 213003])\n",
      "✓ Saved to: C:/zahra/EchoMind/data/result/inference100/english_OJCIvTNk_lightning.wav\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --model MODEL --input\n",
      "                             INPUT --output OUTPUT --prompt\n",
      "                             PROMPT [--dac-model DAC_MODEL]\n",
      "                             [--device DEVICE]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --model, --input, --output, --prompt\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Example usage (can be run directly or via command line)\n",
    "    #C:/Users/user/Downloads/weights_44khz_16kbps.pth\n",
    "    # For direct usage in script:\n",
    "    \n",
    "    model_path = \"C:/zahra/EchoMind/data/result/model_best.pt\"\n",
    "    input_audio = \"C:/zahra/EchoMind/data/result/inference/english_OJCIvTNk.wav\"\n",
    "    output_audio = \"C:/zahra/EchoMind/data/result/inference100/english_OJCIvTNk_lightning.wav\"\n",
    "    effect_prompt = \"add lightning sounds\"\n",
    "    \n",
    "    inference = AudioEffectInference(model_path, dac_model_path=\"C:/Users/user/Downloads/weights_44khz_16kbps.pth\", device='cuda')\n",
    "    inference.process_audio(input_audio, output_audio, effect_prompt)\n",
    "    \n",
    "    # For command line usage:\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7cf3ecb-478a-4beb-8551-57e7784a9027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOADING MODEL FOR INFERENCE (NO AUDIOTOOLS)\n",
      "============================================================\n",
      "Loading checkpoint from: C:/zahra/EchoMind/data/result/model_best.pt\n",
      "✓ Sample rate: 44100 Hz\n",
      "✓ Latent channels: 128\n",
      "✓ UNet channels: [64, 128, 256, 512]\n",
      "Loading DAC model from: C:/Users/user/Downloads/weights_44khz_16kbps.pth\n",
      "✓ DAC model loaded\n",
      "✓ Model weights loaded\n",
      "✓ Tokenizer loaded\n",
      "✓ Device: cuda\n",
      "============================================================\n",
      "\n",
      "Processing: C:/zahra/EchoMind/data/result/inference/arabic_XBmfzfHL.wav\n",
      "Effect: 'add cats sounds'\n",
      "Resampling from 48000 Hz to 44100 Hz\n",
      "Converting to mono\n",
      "Input shape: torch.Size([1, 1, 219618])\n",
      "Generating...\n",
      "Adjusting length: 219136 -> 219618\n",
      "Output shape: torch.Size([1, 219618])\n",
      "✓ Saved to: C:/zahra/EchoMind/data/result/inference100/arabic_XBmfzfHL_cats.wav\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --model MODEL --input\n",
      "                             INPUT --output OUTPUT --prompt\n",
      "                             PROMPT [--dac-model DAC_MODEL]\n",
      "                             [--device DEVICE]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --model, --input, --output, --prompt\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Example usage (can be run directly or via command line)\n",
    "    #C:/Users/user/Downloads/weights_44khz_16kbps.pth\n",
    "    # For direct usage in script:\n",
    "    \n",
    "    model_path = \"C:/zahra/EchoMind/data/result/model_best.pt\"\n",
    "    input_audio = \"C:/zahra/EchoMind/data/result/inference/arabic_XBmfzfHL.wav\"\n",
    "    output_audio = \"C:/zahra/EchoMind/data/result/inference100/arabic_XBmfzfHL_cats.wav\"\n",
    "    effect_prompt = \"add cats sounds\"\n",
    "    \n",
    "    inference = AudioEffectInference(model_path, dac_model_path=\"C:/Users/user/Downloads/weights_44khz_16kbps.pth\", device='cuda')\n",
    "    inference.process_audio(input_audio, output_audio, effect_prompt)\n",
    "    \n",
    "    # For command line usage:\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c5c2145-363e-40b6-85d9-3a07afaae9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOADING MODEL FOR INFERENCE (NO AUDIOTOOLS)\n",
      "============================================================\n",
      "Loading checkpoint from: C:/zahra/EchoMind/data/result/model_best.pt\n",
      "✓ Sample rate: 44100 Hz\n",
      "✓ Latent channels: 128\n",
      "✓ UNet channels: [64, 128, 256, 512]\n",
      "Loading DAC model from: C:/Users/user/Downloads/weights_44khz_16kbps.pth\n",
      "✓ DAC model loaded\n",
      "✓ Model weights loaded\n",
      "✓ Tokenizer loaded\n",
      "✓ Device: cuda\n",
      "============================================================\n",
      "\n",
      "Processing: C:/zahra/EchoMind/data/result/inference/bouchra.ogg\n",
      "Effect: 'add lightning sounds'\n",
      "Resampling from 16000 Hz to 44100 Hz\n",
      "Input shape: torch.Size([1, 1, 209820])\n",
      "Generating...\n",
      "Adjusting length: 209408 -> 209820\n",
      "Output shape: torch.Size([1, 209820])\n",
      "✓ Saved to: C:/zahra/EchoMind/data/result/inference100/bouchra_lightning.wav\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --model MODEL --input\n",
      "                             INPUT --output OUTPUT --prompt\n",
      "                             PROMPT [--dac-model DAC_MODEL]\n",
      "                             [--device DEVICE]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --model, --input, --output, --prompt\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Example usage (can be run directly or via command line)\n",
    "    #C:/Users/user/Downloads/weights_44khz_16kbps.pth\n",
    "    # For direct usage in script:\n",
    "    \n",
    "    model_path = \"C:/zahra/EchoMind/data/result/model_best.pt\"\n",
    "    input_audio = \"C:/zahra/EchoMind/data/result/inference/bouchra.ogg\"\n",
    "    output_audio = \"C:/zahra/EchoMind/data/result/inference100/bouchra_lightning.wav\"\n",
    "    effect_prompt = \"add lightning sounds\"\n",
    "    \n",
    "    inference = AudioEffectInference(model_path, dac_model_path=\"C:/Users/user/Downloads/weights_44khz_16kbps.pth\", device='cuda')\n",
    "    inference.process_audio(input_audio, output_audio, effect_prompt)\n",
    "    \n",
    "    # For command line usage:\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad61cf-6f64-4fe5-9fdd-343bb7731de5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
